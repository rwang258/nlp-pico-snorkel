{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffcb4bb9-12de-4189-85a3-3320ccf9be85",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data programming with Snorkel: Labeling the PICO dataset\n",
    "\n",
    "PICO data from [here](https://ebm-nlp.herokuapp.com/) and [here](https://github.com/bepnye/EBM-NLP). \n",
    "\n",
    "Code by Jacqueline R. M. A. Maasch and Ray Wang | November 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7f85e0-0682-418b-b705-eae6121cb10b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e0a69cf-15ef-45ee-8861-bb873fce2904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importations.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from snorkel.labeling import labeling_function\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling.model import MajorityLabelVoter\n",
    "from snorkel.labeling.model import LabelModel\n",
    "from snorkel.analysis import get_label_buckets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string # For punctuation.\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73489cc0-4414-4ad9-ab40-ffd85d3f34ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Process keyword data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7dc43e5-51bc-4981-9ae5-083734b6a32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in drug name suffixes.\n",
    "# https://druginfo.nlm.nih.gov/drugportal/jsp/drugportal/DrugNameGenericStems.jsp\n",
    "df_drugs = pd.read_csv(\"drug_suffixes.txt\", header = None)\n",
    "# print(df_drugs.info())\n",
    "# display(df_drugs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af011700-5128-4b1d-8845-cf5500184ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in surgical suffixes.\n",
    "# https://en.wikipedia.org/wiki/List_of_surgical_procedures\n",
    "df_surgery = pd.read_csv(\"surgical_suffixes.txt\", header = None)\n",
    "# print(df_surgery.info())\n",
    "# display(df_surgery.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bc0b185-3d96-4fe8-9ff6-753389185823",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in psyocholigical keywords.\n",
    "# https://www.ncbi.nlm.nih.gov/books/NBK385382/\n",
    "df_psych = pd.read_csv(\"psychotherapy_keywords.txt\", header = None)\n",
    "# print(df_psych.info())\n",
    "# display(df_psych.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abbd051b-4ffd-4a9d-8115-9cfb4e4f7b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_surgery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14a4a89e-08f7-48c3-b318-d9b82dbed512",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raywang/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3444: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "b'Skipping line 35225: expected 8 fields, saw 9\\nSkipping line 35226: expected 8 fields, saw 9\\nSkipping line 35227: expected 8 fields, saw 9\\n'\n"
     ]
    }
   ],
   "source": [
    "# Read in FDA data.\n",
    "# Sources: \n",
    "# https://purplebooksearch.fda.gov/downloads\n",
    "# https://www.accessdata.fda.gov/scripts/cder/daf/index.cfm\n",
    "# https://www.fda.gov/drugs/drug-approvals-and-databases/drugsfda-data-files\n",
    "# https://www.fda.gov/drugs/drug-approvals-and-databases/approved-drug-products-therapeutic-\n",
    "#         equivalence-evaluations-orange-book\n",
    "\n",
    "df_purple = pd.read_csv(\"fda_approved_drugs/products_purplebook.csv\")\n",
    "df_orange = pd.read_csv(\"fda_approved_drugs/products_orangebook.txt\", \n",
    "                        sep = \"~\")\n",
    "df_drugs_at_fda = pd.read_csv(\"fda_approved_drugs/products_drugs_at_fda.txt\", \n",
    "                              sep = \"\\t\", \n",
    "                              error_bad_lines = False)\n",
    "\n",
    "# print(df_purple.info())\n",
    "# display(df_purple.head())\n",
    "\n",
    "# print(df_orange.info())\n",
    "# display(df_orange.head())\n",
    "\n",
    "# print(df_drugs_at_fda.info())\n",
    "# display(df_drugs_at_fda.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d65cb622-487c-4872-ab25-87399bfd84b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter drug suffixes with three characters or fewer.\n",
    "drug_suffixes = list(df_drugs[0])\n",
    "drug_suffixes = [x.lower() for x in drug_suffixes if len(x) > 3]\n",
    "# print(len(drug_suffixes), \"drug suffixes of\", len(df_drugs[0]), \"are of adequate length.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5e78dff-ebb4-4857-b1d3-344273d18478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all keywords to lowercase.\n",
    "df_psych[0] = df_psych[0].str.lower()\n",
    "# display(df_psych.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73432812-6063-449f-bfbd-2e8756a4b0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate FDA drug data.\n",
    "set_proprietary = list(df_drugs_at_fda[\"DrugName\"]) + list(df_purple[\"Proprietary Name\"]) + list(df_orange[\"Trade_Name\"])\n",
    "set_proper = list(df_drugs_at_fda[\"ActiveIngredient\"]) + list(df_purple[\"Proper Name\"]) + list(df_orange[\"Ingredient\"])\n",
    "\n",
    "# Remove floats and integers.\n",
    "set_proprietary = [item.lower() for item in set_proprietary if not isinstance(item, float)]\n",
    "set_proprietary = [item for item in set_proprietary if not isinstance(item, int)]\n",
    "set_proper = [item.lower() for item in set_proper if not isinstance(item, float)]\n",
    "set_proper = [item for item in set_proper if not isinstance(item, int)]\n",
    "\n",
    "# Length prior to eliminating duplicates.\n",
    "# print(len(set_proprietary))\n",
    "# print(len(set_proper))\n",
    "\n",
    "# Cast as sets to remove duplicates.\n",
    "set_proprietary = set(set_proprietary)\n",
    "set_proper = set(set_proper)\n",
    "\n",
    "set_fda = set.union(set_proprietary, set_proper)\n",
    "\n",
    "# Length after removing duplicates.\n",
    "# print(len(set_proprietary))\n",
    "# print(len(set_proper))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2442c7-c67d-4929-99aa-45f5150a6141",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76f8d1b3-d9ed-41e5-bcf6-b679bb10d932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stores all files as series\n",
    "files_as_series = {}\n",
    "# stores first sentence of all files\n",
    "first_sentence_file = {}\n",
    "# stores all POS files as series\n",
    "pos_files_as_series = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb3423e-f514-4449-8052-40bd906b59f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d83ff6c4-c99c-4121-804e-c70ec452cc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get index of each token in the .txt file this token is from and returns all indexes as a list.\n",
    "def get_indexes_as_series(tokens):\n",
    "    return tokens.index.tolist()\n",
    "    \n",
    "# returns a list of this value of size n, where each value is the \n",
    "# length of the .txt file this token is from, where n is the length of the input tokens series\n",
    "def get_len_as_series(tokens):\n",
    "    temp = [len(tokens) for i in range(0, len(tokens))]\n",
    "    return temp\n",
    "\n",
    "\n",
    "def file_to_series(file_name):    \n",
    "    # Source: https://www.geeksforgeeks.org/read-a-file-line-by-line-in-python/\n",
    "    with open(file_name) as f:\n",
    "        lines = [line.strip() for line in f]\n",
    "    return pd.Series(lines)\n",
    "\n",
    "# Strip PubMed IDs from file names.\n",
    "strip_pmid = lambda x: x.split(\".\")[0]\n",
    "\n",
    "def iter_token_dir(dir_name, df, label_dict, col_name = \"Token\", ext_name = \".tokens\"):\n",
    "    directory = os.fsencode(dir_name)\n",
    "    for file in os.listdir(directory):\n",
    "        file_name = os.fsdecode(file)\n",
    "        if file_name.endswith(ext_name): \n",
    "            \n",
    "            series_file = file_to_series(directory.decode(\"utf-8\") + file_name)\n",
    "            \n",
    "            pos_series_file = file_to_series(directory.decode(\"utf-8\") + file_name.split(\".\")[0] + \".pos\")\n",
    "            \n",
    "            files_as_series[file_name] = series_file\n",
    "            pos_files_as_series[file_name.split(\".\")[0] + \".pos\"] = pos_series_file\n",
    "            \n",
    "            token_index = get_indexes_as_series(series_file)\n",
    "            file_len = get_len_as_series(series_file)\n",
    "                        \n",
    "            PMID = strip_pmid(file_name)\n",
    "            df_file = pd.DataFrame({col_name: series_file,\n",
    "                                    \"File\": [file_name] * len(series_file),\n",
    "                                    \"Gold\": label_dict.get(PMID),\n",
    "                                    \"PMID\": [PMID] * len(series_file),\n",
    "                                    \"token_index\": token_index,\n",
    "                                    \"file_len\": file_len\n",
    "                                   })\n",
    "            df = pd.concat([df, df_file])\n",
    "        else:\n",
    "            continue\n",
    "    return df\n",
    "\n",
    "def iter_label_dir(dir_name, ext_name = \".AGGREGATED.ann\"):\n",
    "    label_dict = dict()\n",
    "    directory = os.fsencode(dir_name)\n",
    "    for file in os.listdir(directory):\n",
    "        file_name = os.fsdecode(file)\n",
    "        if file_name.endswith(ext_name): \n",
    "            series_file = file_to_series(directory.decode(\"utf-8\") + file_name)\n",
    "            PMID = strip_pmid(file_name)\n",
    "            label_dict[PMID] = series_file\n",
    "        else:\n",
    "            continue\n",
    "    return label_dict\n",
    "\n",
    "def get_three_spans(tokens):\n",
    "    span_list = []\n",
    "    span_list.append([tokens[0], tokens[1]])\n",
    "    for i in range(1, len(tokens) - 1):\n",
    "        span_list.append([tokens[i - 1], tokens[i], tokens[i + 1]])\n",
    "    span_list.append([tokens[len(tokens) - 2], tokens[len(tokens) - 1]])\n",
    "    return span_list\n",
    "\n",
    "\n",
    "# get sentence index, sentence, and parts of speech of sentence, that token is in\n",
    "def get_sentence_info(token_index, file_name):\n",
    "        \n",
    "    token_series = files_as_series[file_name]\n",
    "    pos_series = pos_files_as_series[file_name.split(\".\")[0] + \".pos\"]\n",
    "    sentence = []\n",
    "    pos_sentence = []\n",
    "    sentence_index = 0\n",
    "    \n",
    "    i = token_index\n",
    "    while i>=0 and token_series[i]!='.':\n",
    "        sentence.insert(0, token_series[i])\n",
    "        pos_sentence.insert(0, pos_series[i])\n",
    "        i-=1\n",
    "\n",
    "    # index within sentence\n",
    "    sentence_index = token_index - (i+1)\n",
    "    i = token_index+1\n",
    "\n",
    "    while i<len(token_series) and token_series[i]!='.':\n",
    "        sentence.append(token_series[i])\n",
    "        pos_sentence.append(pos_series[i])\n",
    "        i+=1\n",
    "\n",
    "    if token_index==0:\n",
    "        first_sentence_file[file_name] = [x.lower() for x in sentence]\n",
    "            \n",
    "    return (sentence_index, sentence, pos_sentence)\n",
    "\n",
    "def get_sentence_index(x):\n",
    "    i, s, ps = x\n",
    "    return i\n",
    "def get_sentence(x):\n",
    "    i, s, ps = x\n",
    "    return s\n",
    "def get_pos_sentence(x):\n",
    "    i, s, ps = x\n",
    "    return ps\n",
    "\n",
    "# tokens that are punctuation.\n",
    "def is_punctuation(x):\n",
    "    return False if x.Token.lower() in string.punctuation else True\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e33788-aa21-48d6-a27f-f26177eb7a72",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c5f387-b650-4928-92b8-f979352836bf",
   "metadata": {},
   "source": [
    "Construct dataframe to store instances and gold labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f37df9ec-2bae-4c00-959e-b64309cc90a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through directory to obtain all gold labels, \n",
    "# mapped to their respective file names.\n",
    "label_dict = iter_label_dir(\"annotations/aggregated/starting_spans/interventions/train/\")\n",
    "\n",
    "# Iterate through directory to obtain all tokens,\n",
    "# mapped to their respective file names.\n",
    "# original tokens\n",
    "df_orig = pd.DataFrame()\n",
    "df_orig = iter_token_dir(\"documents/\", df_orig, label_dict)\n",
    "# print(df_orig.info())\n",
    "# display(df_orig.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58b2070f-a249-4161-8094-daa4a4ae7900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sample files\n",
    "# files_5 = ['11369627', '9474450', '17365975', '20149953', '25162407']\n",
    "# files_5_sel = df_orig['PMID'].apply(lambda x : x in files_5)\n",
    "\n",
    "files_sample = random.sample(df_orig.PMID.unique().tolist(), 30)\n",
    "files_30_sel = df_orig['PMID'].apply(lambda x : x in files_sample)\n",
    "\n",
    "# original sample files\n",
    "df_sample_orig = df_orig[files_30_sel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bcb22ea-dfc7-4bec-bfd3-89ecfe78f5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cg/7sgq3d_57hdbfbh57wbdgxgc0000gn/T/ipykernel_15444/1797742227.py:25: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df_orig = df_orig.drop(\"sentence_info\", 1)\n",
      "/var/folders/cg/7sgq3d_57hdbfbh57wbdgxgc0000gn/T/ipykernel_15444/1797742227.py:27: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df_sample = df_sample.drop(\"sentence_info\", 1)\n"
     ]
    }
   ],
   "source": [
    "# Remove NA gold labels.\n",
    "df_orig = df_orig.dropna()\n",
    "# new sample files\n",
    "df_sample = df_sample_orig.dropna()\n",
    "\n",
    "df_sample = df_sample.reset_index(drop = True)\n",
    "df_orig = df_orig.reset_index(drop = True)\n",
    "\n",
    "\n",
    "# get sentence related columns for each token\n",
    "df_orig[\"sentence_info\"] = df_orig.apply(lambda x : get_sentence_info(x[\"token_index\"], x[\"File\"]), axis=1)\n",
    "\n",
    "df_sample[\"sentence_info\"] = df_sample.apply(lambda x : get_sentence_info(x[\"token_index\"], x[\"File\"]), axis=1)\n",
    "\n",
    "\n",
    "df_orig[\"sentence_index\"] = df_orig[\"sentence_info\"].apply(get_sentence_index)\n",
    "df_orig[\"sentence\"] = df_orig[\"sentence_info\"].apply(get_sentence)\n",
    "df_orig[\"pos_sentence\"] = df_orig[\"sentence_info\"].apply(get_pos_sentence)\n",
    "\n",
    "\n",
    "df_sample[\"sentence_index\"] = df_sample[\"sentence_info\"].apply(get_sentence_index)\n",
    "df_sample[\"sentence\"] = df_sample[\"sentence_info\"].apply(get_sentence)\n",
    "df_sample[\"pos_sentence\"] = df_sample[\"sentence_info\"].apply(get_pos_sentence)\n",
    "\n",
    "df_orig = df_orig.drop(\"sentence_info\", 1)\n",
    "\n",
    "df_sample = df_sample.drop(\"sentence_info\", 1)\n",
    "\n",
    "# remove punctuation tokens\n",
    "df_orig = df_orig[df_orig.apply(lambda x: is_punctuation(x), axis=1)]\n",
    "\n",
    "df_sample = df_sample[df_sample.apply(lambda x: is_punctuation(x), axis=1)]\n",
    "\n",
    "\n",
    "\n",
    "df_sample = df_sample.reset_index(drop = True)\n",
    "df_orig = df_orig.reset_index(drop = True)\n",
    "\n",
    "\n",
    "\n",
    "df_dev = df_orig.tail(10000).sample(n=1000).reset_index(drop = True)\n",
    "\n",
    "# Random sample for more manageable training.\n",
    "df_dir = df_orig[:-10000].sample(n = 10000).reset_index(drop = True)\n",
    "\n",
    "# Train-test split (80% / 20%, stratified by gold label value).\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_dir[\"Token\"], \n",
    "                                                    df_dir[\"Gold\"], \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 42,\n",
    "                                                    stratify = df_dir[\"Gold\"])\n",
    "df_train = df_dir.iloc[X_train.index].reset_index(drop = True)\n",
    "df_test = df_dir.iloc[X_test.index].reset_index(drop = True)\n",
    "\n",
    "# print(df_train.info())\n",
    "# display(df_train.head())\n",
    "# print(df_test.info())\n",
    "# display(df_test.head())\n",
    "# print(df_dev.info())\n",
    "# display(df_dev.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91caec48-6839-4e1f-b32a-4bcf63765253",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Labeling functions\n",
    "\n",
    "Labeling functions will be written to cover the following intervention categories, as used by the manual annotators of this [dataset](https://github.com/bepnye/EBM-NLP):\n",
    "\n",
    "- Surgical.\n",
    "- Physical.\n",
    "- Drug.\n",
    "- Educational.\n",
    "- Psychological.\n",
    "- Other.\n",
    "- Control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c681538f-de23-409a-a9fd-311493e99fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stop words = 179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/raywang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Label macros.\n",
    "ABSTAIN = -1\n",
    "NOT_I = 0\n",
    "I = 1\n",
    "\n",
    "# Data for labeling functions.\n",
    "generic_interventions = [\"therap\", \"treatment\", \"intervention\",\n",
    "                         \"placebo\", \"dose\", \"control\", \"vaccin\"]\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = stopwords.words(\"english\")\n",
    "print(\"Total stop words =\", len(stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913a3071-c24f-4336-9192-65f1ab5dfe9a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Labeling functions\n",
    "**All labeling functions label tokens. The corresponding gold labels are from the \"starting span\" labels.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b3292de-a337-4cf2-9976-629fafae9335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeling function for tokens, if token is present in first sentence (title)\n",
    "@labeling_function(resources=dict(first_sentence_file=first_sentence_file))\n",
    "def in_title(x, first_sentence_file):\n",
    "    return I if x.Token.lower() in first_sentence_file[x.File] else ABSTAIN\n",
    "# abstain or not_i?\n",
    "\n",
    "# Labeling function for tokens, if token is present in first sentence (title)\n",
    "@labeling_function(resources=dict(first_sentence_file=first_sentence_file))\n",
    "def in_title2(x, first_sentence_file):\n",
    "    return I if x.Token.lower() in first_sentence_file[x.File] else ABSTAIN\n",
    "# abstain or not_i?\n",
    "\n",
    "# Labeling function for tokens, if token is present in first sentence (title)\n",
    "@labeling_function(resources=dict(first_sentence_file=first_sentence_file))\n",
    "def in_title3(x, first_sentence_file):\n",
    "    return I if x.Token.lower() in first_sentence_file[x.File] else ABSTAIN\n",
    "# abstain or not_i?\n",
    "\n",
    "# Labeling function for tokens, if token is present in first sentence (title)\n",
    "@labeling_function(resources=dict(first_sentence_file=first_sentence_file))\n",
    "def in_title4(x, first_sentence_file):\n",
    "    return I if x.Token.lower() in first_sentence_file[x.File] else ABSTAIN\n",
    "# abstain or not_i?\n",
    "\n",
    "\n",
    "# Labeling function for tokens, if token is present in first sentence (title)\n",
    "@labeling_function(resources=dict(first_sentence_file=first_sentence_file))\n",
    "def not_in_title(x, first_sentence_file):\n",
    "    return NOT_I if x.Token.lower() not in first_sentence_file[x.File] else ABSTAIN\n",
    "# abstain or not_i?\n",
    "\n",
    "\n",
    "@labeling_function(resources=dict(first_sentence_file=first_sentence_file))\n",
    "def surround_in_title(x, first_sentence_file):\n",
    "    if((x.sentence_index>0) and (x.sentence_index<len(x.sentence)-1)):\n",
    "        if (x.sentence[x.sentence_index-1].lower() in first_sentence_file[x.File]) and (x.sentence[x.sentence_index+1].lower() in first_sentence_file[x.File]):\n",
    "            return I\n",
    "    \n",
    "    return ABSTAIN\n",
    "# abstain or not_i?\n",
    "\n",
    "\n",
    "# Labeling function for tokens that contain drug suffixes.\n",
    "@labeling_function()\n",
    "def contains_drug_suffix(x):\n",
    "    return I if (any(suffix.lower() in x.Token.lower() for suffix in drug_suffixes)) else ABSTAIN\n",
    "    \n",
    "# Labeling function for tokens that contain surgical suffixes.\n",
    "@labeling_function()\n",
    "def contains_surgical_suffix(x):\n",
    "    return I if (any(suffix.lower() in x.Token.lower() for suffix in df_surgery[0])) else ABSTAIN\n",
    "\n",
    "# Labeling function for tokens that contain psychological / psychotherapeutic keywords.\n",
    "@labeling_function()\n",
    "def contains_psych_term(x):\n",
    "    return I if (any(suffix.lower() in x.Token.lower() for suffix in df_psych[0])) else ABSTAIN\n",
    "\n",
    "# Labeling function for tokens that contain generic intervention keywords.\n",
    "@labeling_function()\n",
    "def is_generic(x):\n",
    "    return I if (any(term.lower() in x.Token.lower() for term in generic_interventions)) else ABSTAIN\n",
    "\n",
    "# Labeling function for stop words.\n",
    "@labeling_function()\n",
    "def is_stop_word(x):\n",
    "    return NOT_I if x.Token.lower() in stop_words else ABSTAIN\n",
    "\n",
    "# Labeling function for tokens that are punctuation.\n",
    "@labeling_function()\n",
    "def is_punctuation(x):\n",
    "    return NOT_I if x.Token.lower() in string.punctuation else ABSTAIN\n",
    "\n",
    "\n",
    "# Labeling function for FDA approved drugs.\n",
    "@labeling_function()\n",
    "def contains_fda_drug(x):\n",
    "    if (len(x.Token) <= 5):\n",
    "        return ABSTAIN\n",
    "\n",
    "    return I if (any(x.Token.lower() in drug.lower() for drug in set_fda)) else ABSTAIN\n",
    "\n",
    "\n",
    "# checks if the preceding token is 'of' or 'with' (effect of... I, treat with... I)\n",
    "@labeling_function()\n",
    "def has_prev_word_as(x):\n",
    "    words = ['of', 'with', 'receive', 'and']\n",
    "    if ((x.sentence_index > 0) and (x.sentence[x.sentence_index-1].lower() in words)):\n",
    "        return I \n",
    "\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "    \n",
    "# checks if the next token is 'group' or 'groups'\n",
    "@labeling_function()\n",
    "def has_next_word_as(x):\n",
    "    words = ['group', 'groups']\n",
    "    if ((x.sentence_index < len(x.sentence)-1) and (x.sentence[x.sentence_index+1].lower() in words)):\n",
    "        return NOT_I\n",
    "\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "    \n",
    "# Labeling function which labels a token as NOT_I if it is in the last 50% of the file tokens.\n",
    "@labeling_function()\n",
    "def has_high_idx(x):\n",
    "    percent = x.token_index / x.file_len\n",
    "    if percent > 0.50:\n",
    "        return NOT_I\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "    \n",
    "    \n",
    "    \n",
    "# Labeling function for tokens, sees if left span of token within sentence contains keyword\n",
    "@labeling_function()\n",
    "def left_span_contains(x):\n",
    "    \n",
    "    i = 0\n",
    "    while(x.sentence[i] != x.Token):\n",
    "        i+=1\n",
    "        \n",
    "    count = 0\n",
    "    while(i >= 0 and count < 10):\n",
    "        if((x.sentence[i] == 'determine') or (x.sentence[i] == 'assess')):\n",
    "            return I\n",
    "        i-=1\n",
    "        count+=1\n",
    "        \n",
    "    return ABSTAIN\n",
    "# look into spouse tutorial left spans, and using 'resources' in LFs\n",
    "\n",
    "\n",
    "# checks if the preceding token is VBD, VBN (e.g. was administered)\n",
    "@labeling_function()\n",
    "def right_span_vb_pos(x):\n",
    "    if (x.sentence_index < len(x.sentence) - 2) and (x.pos_sentence[x.sentence_index+1] == 'VBD') and (x.pos_sentence[x.sentence_index+2] == 'VBN'):\n",
    "        return I \n",
    "\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "    \n",
    "    \n",
    "# checks if the preceding token is VBD, VBN (e.g. was administered)\n",
    "@labeling_function()\n",
    "def left_span_vb_pos(x):\n",
    "    if (x.sentence_index > 0) and ('V' in x.pos_sentence[x.sentence_index-1]):\n",
    "        return I \n",
    "\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "    \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54c1c7b-de98-4d21-99bf-db2a6b0e429d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate Error Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cec4a86-73f0-414a-8e21-82564d62fd94",
   "metadata": {},
   "source": [
    "Incorrect tokens have {* and *} surrounding it. Incorrect is defined as the majority model label being not -1 and different than the gold label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bdaa3337-a6d4-439b-bbd7-b83a97acab17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                          | 2/8152 [00:00<08:11, 16.58it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'length'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cg/7sgq3d_57hdbfbh57wbdgxgc0000gn/T/ipykernel_15444/2306480328.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m       ]\n\u001b[1;32m     32\u001b[0m \u001b[0mapplier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPandasLFApplier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mL_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapplier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Gold\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/snorkel/labeling/apply/pandas.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, df, progress_bar, fault_tolerant, return_meta)\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mcall_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapply_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mlabels_with_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrows_to_triplets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_from_row_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_with_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    812\u001b[0m                 \u001b[0;31m# on the df using our wrapper (which provides bar updating)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8738\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8739\u001b[0m         )\n\u001b[0;32m-> 8740\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8742\u001b[0m     def applymap(\n",
      "\u001b[0;32m~/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m                     \u001b[0;31m# take a fast or slow code path; so stop when t.total==t.n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0;31m# Apply the provided function (in **kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/snorkel/labeling/apply/pandas.py\u001b[0m in \u001b[0;36mapply_lfs_to_data_point\u001b[0;34m(x, lfs, f_caller)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_caller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/snorkel/labeling/apply/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, f, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLabelingFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataPoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfault_tolerant\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/snorkel/labeling/lf/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \"\"\"\n\u001b[1;32m     76\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess_data_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resources\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/cg/7sgq3d_57hdbfbh57wbdgxgc0000gn/T/ipykernel_15444/3426905248.py\u001b[0m in \u001b[0;36msurround_in_title\u001b[0;34m(x, first_sentence_file)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mlabeling_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresources\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_sentence_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfirst_sentence_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msurround_in_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_sentence_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence_index\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence_index\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence_index\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfirst_sentence_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence_index\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfirst_sentence_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'length'"
     ]
    }
   ],
   "source": [
    "# Apply LFs to dataframe.\n",
    "lfs = [\n",
    "       #contains_psych_term, # accuracy = 0.131380\n",
    "       # is_punctuation,\n",
    "       #has_prev_word_as,\n",
    "    \n",
    "       # has_next_word_as_drug, low accuracy and coverage\n",
    "    \n",
    "       # left_span_contains,\n",
    "       # right_span_vb_pos,\n",
    "       # left_span_vb_pos,\n",
    "    \n",
    "       #negative LFs\n",
    "       is_stop_word,\n",
    "       has_next_word_as,\n",
    "       has_high_idx,\n",
    "    \n",
    "       #positive LFs\n",
    "       is_generic,\n",
    "       contains_drug_suffix,\n",
    "       contains_surgical_suffix,\n",
    "       contains_fda_drug,\n",
    "    \n",
    "       in_title,\n",
    "        in_title2,\n",
    "        in_title3,\n",
    "        in_title4,\n",
    "       # not_in_title,\n",
    "       surround_in_title,\n",
    "\n",
    "      ]\n",
    "applier = PandasLFApplier(lfs = lfs)\n",
    "L_train = applier.apply(df = df_sample)\n",
    "Y_train = df_sample[\"Gold\"].to_numpy(dtype = int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b293080b-dbdf-4d96-ac46-b8dac4fe4cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Majority vote model.\n",
    "majority_model = MajorityLabelVoter()\n",
    "preds_train = majority_model.predict(L = L_train)\n",
    "\n",
    "preds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "011c4087-0106-4126-9b46-bff4b27b0597",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['maj_pred']=pd.Series(preds_train.astype(str))\n",
    "df_sample_orig = df_sample_orig.reset_index(drop = True)\n",
    "\n",
    "df_sample_orig['maj_pred'] = '-2'\n",
    "\n",
    "# adding maj_pred column to sample_original\n",
    "for i in range(len(df_sample)):\n",
    "    pmid = df_sample.loc[i, 'PMID']\n",
    "    token_index = df_sample.loc[i, 'token_index']\n",
    "    maj_pred = df_sample.loc[i, 'maj_pred']\n",
    "    ind = df_sample_orig.index[((df_sample_orig['PMID'] == pmid) & (df_sample_orig['token_index'] == token_index))][0]\n",
    "    df_sample_orig.loc[ind, 'maj_pred'] = maj_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "b21f1d2c-e8bc-468e-b553-6b543354f264",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_sample_groups = df_sample_orig.groupby('PMID')\n",
    "\n",
    "# outputting sample files , with tokens that are gold labeled as I highlighted\n",
    "for name, group in df_sample_groups:\n",
    "    with open('gold/' + name + '.md', 'w') as output:\n",
    "        tokens = group.Token.tolist()\n",
    "        golds = group.Gold.tolist()\n",
    "        for i in range(0, len(tokens)):\n",
    "            if(golds[i]=='1'):\n",
    "                output.write('**' + tokens[i] + '** ')\n",
    "            else:\n",
    "                output.write(tokens[i] + ' ')\n",
    "        \n",
    "            \n",
    "            \n",
    "# outputting sample files, with tokens that are missed highlighted (tokens gold labeled as 1, but predicted as 0 or -1)\n",
    "for name, group in df_sample_groups:\n",
    "    with open('missed/' + name + '.md', 'w') as output:\n",
    "        tokens = group.Token.tolist()\n",
    "        golds = group.Gold.tolist()\n",
    "        preds = group.maj_pred.tolist()\n",
    "        for i in range(0, len(tokens)):\n",
    "            if((golds[i]=='1') and ((preds[i]=='-1') or (preds[i]=='0'))):\n",
    "                output.write('**' + tokens[i] + '** ')\n",
    "            else:\n",
    "                output.write(tokens[i] + ' ')\n",
    "                            \n",
    "                    \n",
    "# outputting sample files, with tokens that are mislabeled highlighted\n",
    "for name, group in df_sample_groups:\n",
    "    with open('wrong/' + name + '.md', 'w') as output:\n",
    "        tokens = group.Token.tolist()\n",
    "        golds = group.Gold.tolist()\n",
    "        preds = group.maj_pred.tolist()\n",
    "        for i in range(0, len(tokens)):\n",
    "            if(((golds[i]=='0') and (preds[i]=='1')) or ((golds[i]=='1') and (preds[i]=='0'))):\n",
    "                output.write('**' + tokens[i] + '** ')\n",
    "            else:\n",
    "                output.write(tokens[i] + ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e186e6-5b55-42d8-a953-73acdb04e2bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Apply labeling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e06f424-1595-415c-ac59-e062efbf3789",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 8000/8000 [05:40<00:00, 23.51it/s]\n",
      "100%|███████████████████████████████████████| 2000/2000 [01:13<00:00, 27.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# Apply LFs to dataframe.\n",
    "lfs = [\n",
    "       #contains_psych_term, # accuracy = 0.131380\n",
    "       # is_punctuation,\n",
    "       #has_prev_word_as,\n",
    "    \n",
    "       # has_next_word_as_drug, low accuracy and coverage\n",
    "    \n",
    "       # left_span_contains,\n",
    "       # right_span_vb_pos,\n",
    "       # left_span_vb_pos,\n",
    "    \n",
    "       #negative LFs\n",
    "       is_stop_word,\n",
    "       has_next_word_as,\n",
    "       has_high_idx,\n",
    "    \n",
    "       #positive LFs\n",
    "       is_generic,\n",
    "       contains_drug_suffix,\n",
    "       contains_surgical_suffix,\n",
    "       contains_fda_drug,\n",
    "    \n",
    "       in_title,\n",
    "        in_title2,\n",
    "        in_title3,\n",
    "        in_title4,\n",
    "       # not_in_title,\n",
    "       surround_in_title,\n",
    "\n",
    "      ]\n",
    "applier = PandasLFApplier(lfs = lfs)\n",
    "L_train = applier.apply(df = df_train)\n",
    "L_test = applier.apply(df = df_test)\n",
    "# L_dev = applier.apply(df = df_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "601af81e-1583-4c1c-b8a8-39c21d30fbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#L_train\n",
    "# L_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "63b7fb58-3122-4040-913f-9c3c6f1455ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # %%capture\n",
    "\n",
    "# coverage_check_out, coverage_check = (L_dev != ABSTAIN).mean(axis = 0)\n",
    "# print(f\"check_out coverage: {coverage_check_out * 100:.1f}%\")\n",
    "# print(f\"check coverage: {coverage_check * 100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "2b7ac091-85e1-4b73-b200-98bf96af3ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#L_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c6ea8c7-e289-4499-81b7-524612418c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Y_train, Y_test.\n",
    "Y_train = df_train[\"Gold\"].to_numpy(dtype = int)\n",
    "Y_test = df_test[\"Gold\"].to_numpy(dtype = int)\n",
    "# Y_dev = df_dev[\"Gold\"].to_numpy(dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac65f849-308f-4444-a89a-c0a3324c7510",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raywang/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/Users/raywang/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/Users/raywang/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/Users/raywang/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/Users/raywang/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/Users/raywang/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/Users/raywang/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/Users/raywang/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/Users/raywang/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/Users/raywang/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/Users/raywang/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/Users/raywang/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_stop_word</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.327000</td>\n",
       "      <td>0.230250</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>2497</td>\n",
       "      <td>119</td>\n",
       "      <td>0.954511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_next_word_as</th>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.009250</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>57</td>\n",
       "      <td>17</td>\n",
       "      <td>0.770270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_high_idx</th>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.480625</td>\n",
       "      <td>0.234500</td>\n",
       "      <td>0.120125</td>\n",
       "      <td>3667</td>\n",
       "      <td>178</td>\n",
       "      <td>0.953706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_generic</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>0.015250</td>\n",
       "      <td>0.009125</td>\n",
       "      <td>52</td>\n",
       "      <td>120</td>\n",
       "      <td>0.302326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contains_drug_suffix</th>\n",
       "      <td>4</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.026125</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>0.010375</td>\n",
       "      <td>88</td>\n",
       "      <td>121</td>\n",
       "      <td>0.421053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contains_surgical_suffix</th>\n",
       "      <td>5</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contains_fda_drug</th>\n",
       "      <td>6</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.050875</td>\n",
       "      <td>0.039625</td>\n",
       "      <td>0.021375</td>\n",
       "      <td>141</td>\n",
       "      <td>266</td>\n",
       "      <td>0.346437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_title</th>\n",
       "      <td>7</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.258875</td>\n",
       "      <td>0.258875</td>\n",
       "      <td>0.153250</td>\n",
       "      <td>349</td>\n",
       "      <td>1722</td>\n",
       "      <td>0.168518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_title2</th>\n",
       "      <td>8</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.258875</td>\n",
       "      <td>0.258875</td>\n",
       "      <td>0.153250</td>\n",
       "      <td>349</td>\n",
       "      <td>1722</td>\n",
       "      <td>0.168518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_title3</th>\n",
       "      <td>9</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.258875</td>\n",
       "      <td>0.258875</td>\n",
       "      <td>0.153250</td>\n",
       "      <td>349</td>\n",
       "      <td>1722</td>\n",
       "      <td>0.168518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_title4</th>\n",
       "      <td>10</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.258875</td>\n",
       "      <td>0.258875</td>\n",
       "      <td>0.153250</td>\n",
       "      <td>349</td>\n",
       "      <td>1722</td>\n",
       "      <td>0.168518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surround_in_title</th>\n",
       "      <td>11</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.115125</td>\n",
       "      <td>0.105500</td>\n",
       "      <td>0.047625</td>\n",
       "      <td>154</td>\n",
       "      <td>767</td>\n",
       "      <td>0.167210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           j Polarity  Coverage  Overlaps  Conflicts  Correct  \\\n",
       "is_stop_word               0      [0]  0.327000  0.230250   0.118000     2497   \n",
       "has_next_word_as           1      [0]  0.009250  0.008125   0.004500       57   \n",
       "has_high_idx               2      [0]  0.480625  0.234500   0.120125     3667   \n",
       "is_generic                 3      [1]  0.021500  0.015250   0.009125       52   \n",
       "contains_drug_suffix       4      [1]  0.026125  0.021500   0.010375       88   \n",
       "contains_surgical_suffix   5      [1]  0.002750  0.002250   0.001250        8   \n",
       "contains_fda_drug          6      [1]  0.050875  0.039625   0.021375      141   \n",
       "in_title                   7      [1]  0.258875  0.258875   0.153250      349   \n",
       "in_title2                  8      [1]  0.258875  0.258875   0.153250      349   \n",
       "in_title3                  9      [1]  0.258875  0.258875   0.153250      349   \n",
       "in_title4                 10      [1]  0.258875  0.258875   0.153250      349   \n",
       "surround_in_title         11      [1]  0.115125  0.105500   0.047625      154   \n",
       "\n",
       "                          Incorrect  Emp. Acc.  \n",
       "is_stop_word                    119   0.954511  \n",
       "has_next_word_as                 17   0.770270  \n",
       "has_high_idx                    178   0.953706  \n",
       "is_generic                      120   0.302326  \n",
       "contains_drug_suffix            121   0.421053  \n",
       "contains_surgical_suffix         14   0.363636  \n",
       "contains_fda_drug               266   0.346437  \n",
       "in_title                       1722   0.168518  \n",
       "in_title2                      1722   0.168518  \n",
       "in_title3                      1722   0.168518  \n",
       "in_title4                      1722   0.168518  \n",
       "surround_in_title               767   0.167210  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarive coverage, conflicts, empirical accurcacy of LFs.\n",
    "LFAnalysis(L_train, lfs).lf_summary(Y_train)\n",
    "# LFAnalysis(L_dev, lfs).lf_summary(Y_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65ba588d-1ae3-4208-a3e6-28aefdf2e54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raywang/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/Users/raywang/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/Users/raywang/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/Users/raywang/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/Users/raywang/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/Users/raywang/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/Users/raywang/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/Users/raywang/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/Users/raywang/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/Users/raywang/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/Users/raywang/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/Users/raywang/Desktop/DesktopCover/F2021/CS4999/env/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_stop_word</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.3180</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.1215</td>\n",
       "      <td>592</td>\n",
       "      <td>44</td>\n",
       "      <td>0.930818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_next_word_as</th>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_high_idx</th>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.4805</td>\n",
       "      <td>0.2345</td>\n",
       "      <td>0.1315</td>\n",
       "      <td>913</td>\n",
       "      <td>48</td>\n",
       "      <td>0.950052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_generic</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>0.258065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contains_drug_suffix</th>\n",
       "      <td>4</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.0280</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>24</td>\n",
       "      <td>47</td>\n",
       "      <td>0.338028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contains_surgical_suffix</th>\n",
       "      <td>5</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contains_fda_drug</th>\n",
       "      <td>6</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>37</td>\n",
       "      <td>60</td>\n",
       "      <td>0.381443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_title</th>\n",
       "      <td>7</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.2505</td>\n",
       "      <td>0.2505</td>\n",
       "      <td>0.1555</td>\n",
       "      <td>86</td>\n",
       "      <td>415</td>\n",
       "      <td>0.171657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_title2</th>\n",
       "      <td>8</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.2505</td>\n",
       "      <td>0.2505</td>\n",
       "      <td>0.1555</td>\n",
       "      <td>86</td>\n",
       "      <td>415</td>\n",
       "      <td>0.171657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_title3</th>\n",
       "      <td>9</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.2505</td>\n",
       "      <td>0.2505</td>\n",
       "      <td>0.1555</td>\n",
       "      <td>86</td>\n",
       "      <td>415</td>\n",
       "      <td>0.171657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_title4</th>\n",
       "      <td>10</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.2505</td>\n",
       "      <td>0.2505</td>\n",
       "      <td>0.1555</td>\n",
       "      <td>86</td>\n",
       "      <td>415</td>\n",
       "      <td>0.171657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surround_in_title</th>\n",
       "      <td>11</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.1175</td>\n",
       "      <td>0.1105</td>\n",
       "      <td>0.0545</td>\n",
       "      <td>38</td>\n",
       "      <td>197</td>\n",
       "      <td>0.161702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           j Polarity  Coverage  Overlaps  Conflicts  Correct  \\\n",
       "is_stop_word               0      [0]    0.3180    0.2230     0.1215      592   \n",
       "has_next_word_as           1      [0]    0.0105    0.0090     0.0045       15   \n",
       "has_high_idx               2      [0]    0.4805    0.2345     0.1315      913   \n",
       "is_generic                 3      [1]    0.0155    0.0120     0.0085        8   \n",
       "contains_drug_suffix       4      [1]    0.0355    0.0280     0.0170       24   \n",
       "contains_surgical_suffix   5      [1]    0.0015    0.0015     0.0015        0   \n",
       "contains_fda_drug          6      [1]    0.0485    0.0415     0.0250       37   \n",
       "in_title                   7      [1]    0.2505    0.2505     0.1555       86   \n",
       "in_title2                  8      [1]    0.2505    0.2505     0.1555       86   \n",
       "in_title3                  9      [1]    0.2505    0.2505     0.1555       86   \n",
       "in_title4                 10      [1]    0.2505    0.2505     0.1555       86   \n",
       "surround_in_title         11      [1]    0.1175    0.1105     0.0545       38   \n",
       "\n",
       "                          Incorrect  Emp. Acc.  \n",
       "is_stop_word                     44   0.930818  \n",
       "has_next_word_as                  6   0.714286  \n",
       "has_high_idx                     48   0.950052  \n",
       "is_generic                       23   0.258065  \n",
       "contains_drug_suffix             47   0.338028  \n",
       "contains_surgical_suffix          3   0.000000  \n",
       "contains_fda_drug                60   0.381443  \n",
       "in_title                        415   0.171657  \n",
       "in_title2                       415   0.171657  \n",
       "in_title3                       415   0.171657  \n",
       "in_title4                       415   0.171657  \n",
       "surround_in_title               197   0.161702  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L_test, lfs).lf_summary(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6fa31de-c1ca-4661-a20d-e399b67fa264",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "'''\n",
    "# Explore buckets for patterns in discordance.\n",
    "buckets = get_label_buckets(L_train[:, 0], L_train[:, 1])\n",
    "display(buckets)\n",
    "display(df_train.iloc[buckets[(NOT_I, I)]].sample(10, random_state = 1))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08007c6b-893e-43da-81fa-c8e20261e226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Majority vote model.\n",
    "majority_model = MajorityLabelVoter()\n",
    "preds_train = majority_model.predict(L = L_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29029239-cbc5-460f-a5ce-476ac782e55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label model.\n",
    "label_model = LabelModel(cardinality = 2, verbose = True)\n",
    "label_model.fit(L_train = L_train, n_epochs = 500, log_freq = 100, seed = 123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98745ac8-e558-4350-aff7-beb7cedb758d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute model performance metrics.\n",
    "majority_scores = majority_model.score(L = L_test, Y = Y_test, \n",
    "                                       tie_break_policy = \"random\",\n",
    "                                       metrics = [\"f1\", \"accuracy\", \"precision\", \n",
    "                                                  \"recall\", \"roc_auc\", \"coverage\"])\n",
    "label_scores = label_model.score(L = L_test, Y = Y_test, \n",
    "                                 tie_break_policy = \"random\",\n",
    "                                 metrics = [\"f1\", \"accuracy\", \"precision\", \n",
    "                                            \"recall\", \"roc_auc\", \"coverage\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad7a6fb6-4119-4b0c-91a4-db1ce809f717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Model F1:        24.9%\n",
      "Majority Model Accuracy:  61.4%\n",
      "Majority Model Precision: 15.4%\n",
      "Majority Model Recall:    65.6%\n",
      "Majority Model AUC ROC:   66.3%\n",
      "Majority Model Coverage:  100.0%\n",
      "++++++++++++++++++++++++\n",
      "Label Model F1:           24.2%\n",
      "Label Model Accuracy:     51.9%\n",
      "Label Model Precision:    14.3%\n",
      "Label Model Recall:       78.5%\n",
      "Label Model AUC ROC:      68.3%\n",
      "Label Model Coverage:     100.0%\n"
     ]
    }
   ],
   "source": [
    "# Compare model performance metrics.\n",
    "majority_f1 = majority_scores.get(\"f1\")\n",
    "majority_acc = majority_scores.get(\"accuracy\")\n",
    "majority_prec = majority_scores.get(\"precision\")\n",
    "majority_rec = majority_scores.get(\"recall\")\n",
    "majority_roc = majority_scores.get(\"roc_auc\")\n",
    "majority_cov = majority_scores.get(\"coverage\")\n",
    "print(f\"{'Majority Model F1:':<25} {majority_f1 * 100:.1f}%\")\n",
    "print(f\"{'Majority Model Accuracy:':<25} {majority_acc * 100:.1f}%\")\n",
    "print(f\"{'Majority Model Precision:':<25} {majority_prec * 100:.1f}%\")\n",
    "print(f\"{'Majority Model Recall:':<25} {majority_rec * 100:.1f}%\")\n",
    "print(f\"{'Majority Model AUC ROC:':<25} {majority_roc * 100:.1f}%\")\n",
    "print(f\"{'Majority Model Coverage:':<25} {majority_cov * 100:.1f}%\")\n",
    "print(\"++++++++++++++++++++++++\")\n",
    "\n",
    "label_f1 = label_scores.get(\"f1\")\n",
    "label_acc = label_scores.get(\"accuracy\")\n",
    "label_prec = label_scores.get(\"precision\")\n",
    "label_rec = label_scores.get(\"recall\")\n",
    "label_roc = label_scores.get(\"roc_auc\")\n",
    "label_cov = label_scores.get(\"coverage\")\n",
    "print(f\"{'Label Model F1:':<25} {label_f1 * 100:.1f}%\")\n",
    "print(f\"{'Label Model Accuracy:':<25} {label_acc * 100:.1f}%\")\n",
    "print(f\"{'Label Model Precision:':<25} {label_prec * 100:.1f}%\")\n",
    "print(f\"{'Label Model Recall:':<25} {label_rec * 100:.1f}%\")\n",
    "print(f\"{'Label Model AUC ROC:':<25} {label_roc * 100:.1f}%\")\n",
    "print(f\"{'Label Model Coverage:':<25} {label_cov * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b4c46638-9b8e-4937-8a8e-fd8878554835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy if predicting majority class 0.9025\n"
     ]
    }
   ],
   "source": [
    "# View \"dummy\" accuracy if predicting majority class every time.\n",
    "print(\"Accuracy if predicting majority class\", \n",
    "      df_test[\"Gold\"].value_counts(normalize = True).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dad229-acdc-4be3-a5c1-660cb53d15e0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Explore errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "c694ab7d-3093-4fc5-8803-a5886f64d619",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function(pre=[spacy])\n",
    "def is_noun(x):\n",
    "    if x.doc.pos[0] == 'noun':\n",
    "        return I\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "ae1dea8a-5ca7-4b8d-a0f9-a8e416b98101",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error = df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "3a14e093-8b28-411d-aeed-77b967a83e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>File</th>\n",
       "      <th>Gold</th>\n",
       "      <th>PMID</th>\n",
       "      <th>token_index</th>\n",
       "      <th>file_len</th>\n",
       "      <th>Spans</th>\n",
       "      <th>LF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.</td>\n",
       "      <td>20369616.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>20369616</td>\n",
       "      <td>120</td>\n",
       "      <td>121</td>\n",
       "      <td>[drug, ., Does]</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and</td>\n",
       "      <td>21410033.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>21410033</td>\n",
       "      <td>91</td>\n",
       "      <td>195</td>\n",
       "      <td>[total, and, conjugated]</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quality</td>\n",
       "      <td>15673894.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>15673894</td>\n",
       "      <td>25</td>\n",
       "      <td>308</td>\n",
       "      <td>[the, quality, of]</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>)</td>\n",
       "      <td>1631861.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>1631861</td>\n",
       "      <td>172</td>\n",
       "      <td>218</td>\n",
       "      <td>[9/14, ), .]</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on</td>\n",
       "      <td>20390261.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>20390261</td>\n",
       "      <td>278</td>\n",
       "      <td>293</td>\n",
       "      <td>[effect, on, reversal]</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Token             File Gold      PMID  token_index  file_len  \\\n",
       "0        .  20369616.tokens    0  20369616          120       121   \n",
       "1      and  21410033.tokens    0  21410033           91       195   \n",
       "2  quality  15673894.tokens    0  15673894           25       308   \n",
       "3        )   1631861.tokens    0   1631861          172       218   \n",
       "4       on  20390261.tokens    0  20390261          278       293   \n",
       "\n",
       "                      Spans  LF  \n",
       "0           [drug, ., Does]  -1  \n",
       "1  [total, and, conjugated]  -1  \n",
       "2        [the, quality, of]  -1  \n",
       "3              [9/14, ), .]  -1  \n",
       "4    [effect, on, reversal]  -1  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_error[\"LF\"] = df_error.apply(lambda x: has_next_word_as_drug(x), axis=1)\n",
    "df_error.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "84316461-649a-45fa-8d2c-66f2b1be17bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>File</th>\n",
       "      <th>Gold</th>\n",
       "      <th>PMID</th>\n",
       "      <th>token_index</th>\n",
       "      <th>file_len</th>\n",
       "      <th>Spans</th>\n",
       "      <th>LF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>fentanyl</td>\n",
       "      <td>21935685.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>21935685</td>\n",
       "      <td>147</td>\n",
       "      <td>209</td>\n",
       "      <td>[after, fentanyl, bolus]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>standardized</td>\n",
       "      <td>15264973.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>15264973</td>\n",
       "      <td>65</td>\n",
       "      <td>156</td>\n",
       "      <td>[in, standardized, body]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>anesthesia</td>\n",
       "      <td>18672629.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>18672629</td>\n",
       "      <td>72</td>\n",
       "      <td>265</td>\n",
       "      <td>[general, anesthesia, was]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>triple</td>\n",
       "      <td>24684165.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>24684165</td>\n",
       "      <td>198</td>\n",
       "      <td>337</td>\n",
       "      <td>[the, triple, combination]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>groups</td>\n",
       "      <td>24691455.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>24691455</td>\n",
       "      <td>92</td>\n",
       "      <td>214</td>\n",
       "      <td>[;, groups, B]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>groups</td>\n",
       "      <td>18453793.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>18453793</td>\n",
       "      <td>206</td>\n",
       "      <td>208</td>\n",
       "      <td>[patient, groups, .]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>papillomavirus</td>\n",
       "      <td>17367324.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>17367324</td>\n",
       "      <td>83</td>\n",
       "      <td>283</td>\n",
       "      <td>[human, papillomavirus, infection]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>infant</td>\n",
       "      <td>1741218.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>1741218</td>\n",
       "      <td>221</td>\n",
       "      <td>307</td>\n",
       "      <td>[natural, infant, suckling]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>venous</td>\n",
       "      <td>7211918.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>7211918</td>\n",
       "      <td>12</td>\n",
       "      <td>239</td>\n",
       "      <td>[deep, venous, thrombosis]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>cellular</td>\n",
       "      <td>10607234.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>10607234</td>\n",
       "      <td>404</td>\n",
       "      <td>448</td>\n",
       "      <td>[on, cellular, distribution]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>groups</td>\n",
       "      <td>15960148.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>15960148</td>\n",
       "      <td>250</td>\n",
       "      <td>436</td>\n",
       "      <td>[treatment, groups, pre-randomization]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>groups</td>\n",
       "      <td>9700583.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>9700583</td>\n",
       "      <td>303</td>\n",
       "      <td>437</td>\n",
       "      <td>[both, groups, ,]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>active</td>\n",
       "      <td>7032533.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>7032533</td>\n",
       "      <td>138</td>\n",
       "      <td>318</td>\n",
       "      <td>[the, active, drug]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>reduce</td>\n",
       "      <td>12614412.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>12614412</td>\n",
       "      <td>260</td>\n",
       "      <td>277</td>\n",
       "      <td>[to, reduce, the]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>solution</td>\n",
       "      <td>9587285.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>9587285</td>\n",
       "      <td>140</td>\n",
       "      <td>157</td>\n",
       "      <td>[each, solution, .]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>plasma</td>\n",
       "      <td>22129897.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>22129897</td>\n",
       "      <td>174</td>\n",
       "      <td>234</td>\n",
       "      <td>[in, plasma, sulfate]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>nicotine</td>\n",
       "      <td>25542917.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>25542917</td>\n",
       "      <td>274</td>\n",
       "      <td>301</td>\n",
       "      <td>[with, nicotine, exposure]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>recombinant</td>\n",
       "      <td>7635420.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>7635420</td>\n",
       "      <td>153</td>\n",
       "      <td>323</td>\n",
       "      <td>[,, recombinant, IL-2]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>sodium</td>\n",
       "      <td>23535873.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>23535873</td>\n",
       "      <td>205</td>\n",
       "      <td>303</td>\n",
       "      <td>[of, sodium, bicarbonate]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>kidney</td>\n",
       "      <td>15610252.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>15610252</td>\n",
       "      <td>187</td>\n",
       "      <td>296</td>\n",
       "      <td>[without, kidney, disease]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>single</td>\n",
       "      <td>25162407.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>25162407</td>\n",
       "      <td>293</td>\n",
       "      <td>395</td>\n",
       "      <td>[20-times, single, leg]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>groups</td>\n",
       "      <td>22324448.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>22324448</td>\n",
       "      <td>146</td>\n",
       "      <td>351</td>\n",
       "      <td>[two, groups, were]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>migraine</td>\n",
       "      <td>19570717.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>19570717</td>\n",
       "      <td>222</td>\n",
       "      <td>319</td>\n",
       "      <td>[median, migraine, headache]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>breath</td>\n",
       "      <td>10848655.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>10848655</td>\n",
       "      <td>153</td>\n",
       "      <td>414</td>\n",
       "      <td>[13C-urea, breath, test]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>prothrombin</td>\n",
       "      <td>375690.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>375690</td>\n",
       "      <td>135</td>\n",
       "      <td>192</td>\n",
       "      <td>[Plasma, prothrombin, and]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>activated</td>\n",
       "      <td>23205521.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>23205521</td>\n",
       "      <td>36</td>\n",
       "      <td>210</td>\n",
       "      <td>[experimentally, activated, self-face]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>reduced</td>\n",
       "      <td>23365106.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>23365106</td>\n",
       "      <td>156</td>\n",
       "      <td>395</td>\n",
       "      <td>[alone, reduced, (]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>headache</td>\n",
       "      <td>19570717.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>19570717</td>\n",
       "      <td>123</td>\n",
       "      <td>319</td>\n",
       "      <td>[of, headache, .]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>intravenous</td>\n",
       "      <td>25840597.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>25840597</td>\n",
       "      <td>216</td>\n",
       "      <td>250</td>\n",
       "      <td>[with, intravenous, bortezomib]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>groups</td>\n",
       "      <td>9513236.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>9513236</td>\n",
       "      <td>42</td>\n",
       "      <td>346</td>\n",
       "      <td>[surgery, groups, .]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>hepatitis</td>\n",
       "      <td>26166077.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>26166077</td>\n",
       "      <td>269</td>\n",
       "      <td>288</td>\n",
       "      <td>[chronic, hepatitis, B]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>reduction</td>\n",
       "      <td>1527133.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>1527133</td>\n",
       "      <td>100</td>\n",
       "      <td>156</td>\n",
       "      <td>[relative, reduction, of]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>fraction</td>\n",
       "      <td>8387067.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>8387067</td>\n",
       "      <td>227</td>\n",
       "      <td>271</td>\n",
       "      <td>[large, fraction, size]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372</th>\n",
       "      <td>length</td>\n",
       "      <td>8614420.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>8614420</td>\n",
       "      <td>98</td>\n",
       "      <td>276</td>\n",
       "      <td>[median, length, of]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <td>children</td>\n",
       "      <td>11535502.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>11535502</td>\n",
       "      <td>80</td>\n",
       "      <td>337</td>\n",
       "      <td>[younger, children, were]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>groups</td>\n",
       "      <td>24824660.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>24824660</td>\n",
       "      <td>238</td>\n",
       "      <td>309</td>\n",
       "      <td>[combining, groups, ,]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>children</td>\n",
       "      <td>21787048.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>21787048</td>\n",
       "      <td>404</td>\n",
       "      <td>413</td>\n",
       "      <td>[in, children, who]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>topical</td>\n",
       "      <td>12271298.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>12271298</td>\n",
       "      <td>20</td>\n",
       "      <td>206</td>\n",
       "      <td>[of, topical, anesthetics]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>aspirin</td>\n",
       "      <td>21996146.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>21996146</td>\n",
       "      <td>27</td>\n",
       "      <td>463</td>\n",
       "      <td>[of, aspirin, and]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>treated</td>\n",
       "      <td>23802768.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>23802768</td>\n",
       "      <td>94</td>\n",
       "      <td>275</td>\n",
       "      <td>[melanoma, treated, with]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>rapacuronium</td>\n",
       "      <td>10992833.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>10992833</td>\n",
       "      <td>192</td>\n",
       "      <td>316</td>\n",
       "      <td>[of, rapacuronium, was]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>standard</td>\n",
       "      <td>26040302.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>26040302</td>\n",
       "      <td>193</td>\n",
       "      <td>378</td>\n",
       "      <td>[±, standard, error]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>against</td>\n",
       "      <td>17388667.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>17388667</td>\n",
       "      <td>94</td>\n",
       "      <td>727</td>\n",
       "      <td>[protect, against, prostate]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956</th>\n",
       "      <td>secretin</td>\n",
       "      <td>20337981.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>20337981</td>\n",
       "      <td>230</td>\n",
       "      <td>274</td>\n",
       "      <td>[in, secretin, level]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>groups</td>\n",
       "      <td>20537413.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>20537413</td>\n",
       "      <td>157</td>\n",
       "      <td>208</td>\n",
       "      <td>[Both, groups, improved]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>rating</td>\n",
       "      <td>24345834.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>24345834</td>\n",
       "      <td>258</td>\n",
       "      <td>313</td>\n",
       "      <td>[average, rating, of]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>factor</td>\n",
       "      <td>11154142.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>11154142</td>\n",
       "      <td>87</td>\n",
       "      <td>245</td>\n",
       "      <td>[total, factor, VII]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>tracheal</td>\n",
       "      <td>22585469.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>22585469</td>\n",
       "      <td>47</td>\n",
       "      <td>338</td>\n",
       "      <td>[comparable, tracheal, intubation]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>complete</td>\n",
       "      <td>20008622.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>20008622</td>\n",
       "      <td>136</td>\n",
       "      <td>328</td>\n",
       "      <td>[and, complete, cytogenetic]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2183</th>\n",
       "      <td>groups</td>\n",
       "      <td>12459663.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>12459663</td>\n",
       "      <td>320</td>\n",
       "      <td>379</td>\n",
       "      <td>[three, groups, with]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Token             File Gold      PMID  token_index  file_len  \\\n",
       "54          fentanyl  21935685.tokens    0  21935685          147       209   \n",
       "125     standardized  15264973.tokens    0  15264973           65       156   \n",
       "183       anesthesia  18672629.tokens    0  18672629           72       265   \n",
       "236           triple  24684165.tokens    0  24684165          198       337   \n",
       "288           groups  24691455.tokens    0  24691455           92       214   \n",
       "314           groups  18453793.tokens    0  18453793          206       208   \n",
       "353   papillomavirus  17367324.tokens    0  17367324           83       283   \n",
       "408           infant   1741218.tokens    0   1741218          221       307   \n",
       "459           venous   7211918.tokens    0   7211918           12       239   \n",
       "464         cellular  10607234.tokens    0  10607234          404       448   \n",
       "552           groups  15960148.tokens    0  15960148          250       436   \n",
       "604           groups   9700583.tokens    0   9700583          303       437   \n",
       "634           active   7032533.tokens    0   7032533          138       318   \n",
       "727           reduce  12614412.tokens    0  12614412          260       277   \n",
       "735         solution   9587285.tokens    0   9587285          140       157   \n",
       "792           plasma  22129897.tokens    0  22129897          174       234   \n",
       "875         nicotine  25542917.tokens    0  25542917          274       301   \n",
       "876      recombinant   7635420.tokens    0   7635420          153       323   \n",
       "905           sodium  23535873.tokens    0  23535873          205       303   \n",
       "963           kidney  15610252.tokens    0  15610252          187       296   \n",
       "1097          single  25162407.tokens    0  25162407          293       395   \n",
       "1109          groups  22324448.tokens    0  22324448          146       351   \n",
       "1179        migraine  19570717.tokens    0  19570717          222       319   \n",
       "1193          breath  10848655.tokens    0  10848655          153       414   \n",
       "1253     prothrombin    375690.tokens    0    375690          135       192   \n",
       "1254       activated  23205521.tokens    0  23205521           36       210   \n",
       "1261         reduced  23365106.tokens    0  23365106          156       395   \n",
       "1288        headache  19570717.tokens    0  19570717          123       319   \n",
       "1298     intravenous  25840597.tokens    0  25840597          216       250   \n",
       "1306          groups   9513236.tokens    0   9513236           42       346   \n",
       "1325       hepatitis  26166077.tokens    0  26166077          269       288   \n",
       "1331       reduction   1527133.tokens    0   1527133          100       156   \n",
       "1337        fraction   8387067.tokens    0   8387067          227       271   \n",
       "1372          length   8614420.tokens    0   8614420           98       276   \n",
       "1380        children  11535502.tokens    0  11535502           80       337   \n",
       "1389          groups  24824660.tokens    0  24824660          238       309   \n",
       "1413        children  21787048.tokens    0  21787048          404       413   \n",
       "1418         topical  12271298.tokens    0  12271298           20       206   \n",
       "1494         aspirin  21996146.tokens    0  21996146           27       463   \n",
       "1557         treated  23802768.tokens    0  23802768           94       275   \n",
       "1631    rapacuronium  10992833.tokens    0  10992833          192       316   \n",
       "1723        standard  26040302.tokens    0  26040302          193       378   \n",
       "1795         against  17388667.tokens    0  17388667           94       727   \n",
       "1956        secretin  20337981.tokens    0  20337981          230       274   \n",
       "1994          groups  20537413.tokens    0  20537413          157       208   \n",
       "2009          rating  24345834.tokens    0  24345834          258       313   \n",
       "2014          factor  11154142.tokens    0  11154142           87       245   \n",
       "2131        tracheal  22585469.tokens    0  22585469           47       338   \n",
       "2144        complete  20008622.tokens    0  20008622          136       328   \n",
       "2183          groups  12459663.tokens    0  12459663          320       379   \n",
       "\n",
       "                                       Spans  LF  \n",
       "54                  [after, fentanyl, bolus]   1  \n",
       "125                 [in, standardized, body]   1  \n",
       "183               [general, anesthesia, was]   1  \n",
       "236               [the, triple, combination]   1  \n",
       "288                           [;, groups, B]   1  \n",
       "314                     [patient, groups, .]   1  \n",
       "353       [human, papillomavirus, infection]   1  \n",
       "408              [natural, infant, suckling]   1  \n",
       "459               [deep, venous, thrombosis]   1  \n",
       "464             [on, cellular, distribution]   1  \n",
       "552   [treatment, groups, pre-randomization]   1  \n",
       "604                        [both, groups, ,]   1  \n",
       "634                      [the, active, drug]   1  \n",
       "727                        [to, reduce, the]   1  \n",
       "735                      [each, solution, .]   1  \n",
       "792                    [in, plasma, sulfate]   1  \n",
       "875               [with, nicotine, exposure]   1  \n",
       "876                   [,, recombinant, IL-2]   1  \n",
       "905                [of, sodium, bicarbonate]   1  \n",
       "963               [without, kidney, disease]   1  \n",
       "1097                 [20-times, single, leg]   1  \n",
       "1109                     [two, groups, were]   1  \n",
       "1179            [median, migraine, headache]   1  \n",
       "1193                [13C-urea, breath, test]   1  \n",
       "1253              [Plasma, prothrombin, and]   1  \n",
       "1254  [experimentally, activated, self-face]   1  \n",
       "1261                     [alone, reduced, (]   1  \n",
       "1288                       [of, headache, .]   1  \n",
       "1298         [with, intravenous, bortezomib]   1  \n",
       "1306                    [surgery, groups, .]   1  \n",
       "1325                 [chronic, hepatitis, B]   1  \n",
       "1331               [relative, reduction, of]   1  \n",
       "1337                 [large, fraction, size]   1  \n",
       "1372                    [median, length, of]   1  \n",
       "1380               [younger, children, were]   1  \n",
       "1389                  [combining, groups, ,]   1  \n",
       "1413                     [in, children, who]   1  \n",
       "1418              [of, topical, anesthetics]   1  \n",
       "1494                      [of, aspirin, and]   1  \n",
       "1557               [melanoma, treated, with]   1  \n",
       "1631                 [of, rapacuronium, was]   1  \n",
       "1723                    [±, standard, error]   1  \n",
       "1795            [protect, against, prostate]   1  \n",
       "1956                   [in, secretin, level]   1  \n",
       "1994                [Both, groups, improved]   1  \n",
       "2009                   [average, rating, of]   1  \n",
       "2014                    [total, factor, VII]   1  \n",
       "2131      [comparable, tracheal, intubation]   1  \n",
       "2144            [and, complete, cytogenetic]   1  \n",
       "2183                   [three, groups, with]   1  "
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel = (df_error.LF == 1) & (df_error.Gold == '0') \n",
    "# labeled as NOT_I when actually I => 0 instances\n",
    "# labeled as I when actually NOT_I => non-zero\n",
    "df_error[sel].head(50)\n",
    "# df_orig[(df_orig.PMID=='3385217') & (df_orig.Gold=='1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef63637-5f9c-4641-af97-5a0a9dd2fc03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>File</th>\n",
       "      <th>Gold</th>\n",
       "      <th>PMID</th>\n",
       "      <th>token_index</th>\n",
       "      <th>file_len</th>\n",
       "      <th>Spans</th>\n",
       "      <th>Surgical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>surgery</td>\n",
       "      <td>19092729.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>19092729</td>\n",
       "      <td>17</td>\n",
       "      <td>332</td>\n",
       "      <td>[buckling, surgery, .]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>surgery</td>\n",
       "      <td>24532106.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>24532106</td>\n",
       "      <td>219</td>\n",
       "      <td>280</td>\n",
       "      <td>[after, surgery, ,]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>surgery</td>\n",
       "      <td>15616772.tokens</td>\n",
       "      <td>1</td>\n",
       "      <td>15616772</td>\n",
       "      <td>147</td>\n",
       "      <td>336</td>\n",
       "      <td>[(, surgery, only]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110</th>\n",
       "      <td>surgery</td>\n",
       "      <td>10078673.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>10078673</td>\n",
       "      <td>62</td>\n",
       "      <td>291</td>\n",
       "      <td>[abdominal, surgery, were]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141</th>\n",
       "      <td>surgery</td>\n",
       "      <td>9278836.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>9278836</td>\n",
       "      <td>254</td>\n",
       "      <td>434</td>\n",
       "      <td>[of, surgery, .]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3172</th>\n",
       "      <td>surgery</td>\n",
       "      <td>9278836.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>9278836</td>\n",
       "      <td>266</td>\n",
       "      <td>434</td>\n",
       "      <td>[of, surgery, ,]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5358</th>\n",
       "      <td>surgery</td>\n",
       "      <td>8604728.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>8604728</td>\n",
       "      <td>170</td>\n",
       "      <td>316</td>\n",
       "      <td>[filtering, surgery, group]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5837</th>\n",
       "      <td>surgery</td>\n",
       "      <td>14567804.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>14567804</td>\n",
       "      <td>86</td>\n",
       "      <td>240</td>\n",
       "      <td>[Before, surgery, ,]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7105</th>\n",
       "      <td>surgery</td>\n",
       "      <td>18779477.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>18779477</td>\n",
       "      <td>202</td>\n",
       "      <td>310</td>\n",
       "      <td>[glaucoma, surgery, was]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7944</th>\n",
       "      <td>surgery</td>\n",
       "      <td>11214014.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>11214014</td>\n",
       "      <td>12</td>\n",
       "      <td>306</td>\n",
       "      <td>[bypass, surgery, .]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7945</th>\n",
       "      <td>surgery</td>\n",
       "      <td>8823584.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>8823584</td>\n",
       "      <td>356</td>\n",
       "      <td>358</td>\n",
       "      <td>[segment, surgery, .]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8319</th>\n",
       "      <td>surgery</td>\n",
       "      <td>8367775.tokens</td>\n",
       "      <td>1</td>\n",
       "      <td>8367775</td>\n",
       "      <td>82</td>\n",
       "      <td>323</td>\n",
       "      <td>[spinal, surgery, .]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8858</th>\n",
       "      <td>surgery</td>\n",
       "      <td>9572066.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>9572066</td>\n",
       "      <td>329</td>\n",
       "      <td>364</td>\n",
       "      <td>[cardiac, surgery, .]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9928</th>\n",
       "      <td>surgery</td>\n",
       "      <td>12049860.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>12049860</td>\n",
       "      <td>92</td>\n",
       "      <td>285</td>\n",
       "      <td>[hip-replacement, surgery, to]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Token             File Gold      PMID  token_index  file_len  \\\n",
       "250   surgery  19092729.tokens    0  19092729           17       332   \n",
       "834   surgery  24532106.tokens    0  24532106          219       280   \n",
       "1130  surgery  15616772.tokens    1  15616772          147       336   \n",
       "2110  surgery  10078673.tokens    0  10078673           62       291   \n",
       "3141  surgery   9278836.tokens    0   9278836          254       434   \n",
       "3172  surgery   9278836.tokens    0   9278836          266       434   \n",
       "5358  surgery   8604728.tokens    0   8604728          170       316   \n",
       "5837  surgery  14567804.tokens    0  14567804           86       240   \n",
       "7105  surgery  18779477.tokens    0  18779477          202       310   \n",
       "7944  surgery  11214014.tokens    0  11214014           12       306   \n",
       "7945  surgery   8823584.tokens    0   8823584          356       358   \n",
       "8319  surgery   8367775.tokens    1   8367775           82       323   \n",
       "8858  surgery   9572066.tokens    0   9572066          329       364   \n",
       "9928  surgery  12049860.tokens    0  12049860           92       285   \n",
       "\n",
       "                               Spans  Surgical  \n",
       "250           [buckling, surgery, .]         1  \n",
       "834              [after, surgery, ,]         1  \n",
       "1130              [(, surgery, only]         1  \n",
       "2110      [abdominal, surgery, were]         1  \n",
       "3141                [of, surgery, .]         1  \n",
       "3172                [of, surgery, ,]         1  \n",
       "5358     [filtering, surgery, group]         1  \n",
       "5837            [Before, surgery, ,]         1  \n",
       "7105        [glaucoma, surgery, was]         1  \n",
       "7944            [bypass, surgery, .]         1  \n",
       "7945           [segment, surgery, .]         1  \n",
       "8319            [spinal, surgery, .]         1  \n",
       "8858           [cardiac, surgery, .]         1  \n",
       "9928  [hip-replacement, surgery, to]         1  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test.Token == 'surgery']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f2ca6be2-0c9e-459e-b8db-c2044bb2c084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>File</th>\n",
       "      <th>Gold</th>\n",
       "      <th>PMID</th>\n",
       "      <th>Spans</th>\n",
       "      <th>Surgical</th>\n",
       "      <th>Surgical Concord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>was</td>\n",
       "      <td>7562882.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>7562882</td>\n",
       "      <td>[lisinopril, was, observed]</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mortality</td>\n",
       "      <td>3139179.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>3139179</td>\n",
       "      <td>[RESULTS, Mortality, from]</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.</td>\n",
       "      <td>24077211.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>24077211</td>\n",
       "      <td>[trial, ., OBJECTIVE]</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>compared</td>\n",
       "      <td>10356632.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>10356632</td>\n",
       "      <td>[and, compared, to]</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>25542620.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>25542620</td>\n",
       "      <td>[:, a, randomised]</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Token             File  Gold      PMID                        Spans  \\\n",
       "0        was   7562882.tokens     0   7562882  [lisinopril, was, observed]   \n",
       "1  Mortality   3139179.tokens     0   3139179   [RESULTS, Mortality, from]   \n",
       "2          .  24077211.tokens     0  24077211        [trial, ., OBJECTIVE]   \n",
       "3   compared  10356632.tokens     0  10356632          [and, compared, to]   \n",
       "4          a  25542620.tokens     0  25542620           [:, a, randomised]   \n",
       "\n",
       "   Surgical  Surgical Concord  \n",
       "0        -1                 0  \n",
       "1        -1                 0  \n",
       "2        -1                 0  \n",
       "3        -1                 0  \n",
       "4        -1                 0  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"Gold\"] = df_test[\"Gold\"].astype(int)\n",
    "df_test[\"Surgical Concord\"] = np.where((df_test[\"Gold\"] == df_test[\"Surgical\"]), 1, 0)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6557c906-7c1a-454f-84f5-7b0b72037ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>File</th>\n",
       "      <th>Gold</th>\n",
       "      <th>PMID</th>\n",
       "      <th>Spans</th>\n",
       "      <th>Surgical</th>\n",
       "      <th>Surgical Concord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>surgery</td>\n",
       "      <td>7956382.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>7956382</td>\n",
       "      <td>[), surgery, with]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>surgery</td>\n",
       "      <td>1670445.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>1670445</td>\n",
       "      <td>[hip, surgery, .]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>neuropsychiatric</td>\n",
       "      <td>17513813.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>17513813</td>\n",
       "      <td>[severe, neuropsychiatric, toxicity]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>ureteroscopy</td>\n",
       "      <td>17156222.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>17156222</td>\n",
       "      <td>[(, ureteroscopy, )]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3570</th>\n",
       "      <td>endoscopy</td>\n",
       "      <td>12233894.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>12233894</td>\n",
       "      <td>[gastric, endoscopy, scores]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4036</th>\n",
       "      <td>surgical</td>\n",
       "      <td>15523393.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>15523393</td>\n",
       "      <td>[The, surgical, resection]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204</th>\n",
       "      <td>surgical</td>\n",
       "      <td>11922398.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>11922398</td>\n",
       "      <td>[the, surgical, procedure]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6842</th>\n",
       "      <td>arthroscopy</td>\n",
       "      <td>12882611.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>12882611</td>\n",
       "      <td>[requiring, arthroscopy, were]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7177</th>\n",
       "      <td>surgery</td>\n",
       "      <td>24532106.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>24532106</td>\n",
       "      <td>[before, surgery, .]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7250</th>\n",
       "      <td>surgery</td>\n",
       "      <td>21389925.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>21389925</td>\n",
       "      <td>[\", surgery, .]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7274</th>\n",
       "      <td>surgery</td>\n",
       "      <td>17618948.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>17618948</td>\n",
       "      <td>[after, surgery, ,]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7717</th>\n",
       "      <td>biopsy</td>\n",
       "      <td>18837418.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>18837418</td>\n",
       "      <td>[the, biopsy, specimen]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7880</th>\n",
       "      <td>surgery</td>\n",
       "      <td>25623276.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>25623276</td>\n",
       "      <td>[colorectal, surgery, associated]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Token             File  Gold      PMID  \\\n",
       "13             surgery   7956382.tokens     0   7956382   \n",
       "428            surgery   1670445.tokens     0   1670445   \n",
       "1066  neuropsychiatric  17513813.tokens     0  17513813   \n",
       "1954      ureteroscopy  17156222.tokens     0  17156222   \n",
       "3570         endoscopy  12233894.tokens     0  12233894   \n",
       "4036          surgical  15523393.tokens     0  15523393   \n",
       "5204          surgical  11922398.tokens     0  11922398   \n",
       "6842       arthroscopy  12882611.tokens     0  12882611   \n",
       "7177           surgery  24532106.tokens     0  24532106   \n",
       "7250           surgery  21389925.tokens     0  21389925   \n",
       "7274           surgery  17618948.tokens     0  17618948   \n",
       "7717            biopsy  18837418.tokens     0  18837418   \n",
       "7880           surgery  25623276.tokens     0  25623276   \n",
       "\n",
       "                                     Spans  Surgical  Surgical Concord  \n",
       "13                      [), surgery, with]         1                 0  \n",
       "428                      [hip, surgery, .]         1                 0  \n",
       "1066  [severe, neuropsychiatric, toxicity]         1                 0  \n",
       "1954                  [(, ureteroscopy, )]         1                 0  \n",
       "3570          [gastric, endoscopy, scores]         1                 0  \n",
       "4036            [The, surgical, resection]         1                 0  \n",
       "5204            [the, surgical, procedure]         1                 0  \n",
       "6842        [requiring, arthroscopy, were]         1                 0  \n",
       "7177                  [before, surgery, .]         1                 0  \n",
       "7250                       [\", surgery, .]         1                 0  \n",
       "7274                   [after, surgery, ,]         1                 0  \n",
       "7717               [the, biopsy, specimen]         1                 0  \n",
       "7880     [colorectal, surgery, associated]         1                 0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>File</th>\n",
       "      <th>Gold</th>\n",
       "      <th>PMID</th>\n",
       "      <th>Spans</th>\n",
       "      <th>Surgical</th>\n",
       "      <th>Surgical Concord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>surgery</td>\n",
       "      <td>7956382.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>7956382</td>\n",
       "      <td>[), surgery, with]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>surgery</td>\n",
       "      <td>1670445.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>1670445</td>\n",
       "      <td>[hip, surgery, .]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>neuropsychiatric</td>\n",
       "      <td>17513813.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>17513813</td>\n",
       "      <td>[severe, neuropsychiatric, toxicity]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>ureteroscopy</td>\n",
       "      <td>17156222.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>17156222</td>\n",
       "      <td>[(, ureteroscopy, )]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3570</th>\n",
       "      <td>endoscopy</td>\n",
       "      <td>12233894.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>12233894</td>\n",
       "      <td>[gastric, endoscopy, scores]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4036</th>\n",
       "      <td>surgical</td>\n",
       "      <td>15523393.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>15523393</td>\n",
       "      <td>[The, surgical, resection]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204</th>\n",
       "      <td>surgical</td>\n",
       "      <td>11922398.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>11922398</td>\n",
       "      <td>[the, surgical, procedure]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6842</th>\n",
       "      <td>arthroscopy</td>\n",
       "      <td>12882611.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>12882611</td>\n",
       "      <td>[requiring, arthroscopy, were]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7177</th>\n",
       "      <td>surgery</td>\n",
       "      <td>24532106.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>24532106</td>\n",
       "      <td>[before, surgery, .]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7250</th>\n",
       "      <td>surgery</td>\n",
       "      <td>21389925.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>21389925</td>\n",
       "      <td>[\", surgery, .]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7274</th>\n",
       "      <td>surgery</td>\n",
       "      <td>17618948.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>17618948</td>\n",
       "      <td>[after, surgery, ,]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7717</th>\n",
       "      <td>biopsy</td>\n",
       "      <td>18837418.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>18837418</td>\n",
       "      <td>[the, biopsy, specimen]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7880</th>\n",
       "      <td>surgery</td>\n",
       "      <td>25623276.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>25623276</td>\n",
       "      <td>[colorectal, surgery, associated]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Token             File  Gold      PMID  \\\n",
       "13             surgery   7956382.tokens     0   7956382   \n",
       "428            surgery   1670445.tokens     0   1670445   \n",
       "1066  neuropsychiatric  17513813.tokens     0  17513813   \n",
       "1954      ureteroscopy  17156222.tokens     0  17156222   \n",
       "3570         endoscopy  12233894.tokens     0  12233894   \n",
       "4036          surgical  15523393.tokens     0  15523393   \n",
       "5204          surgical  11922398.tokens     0  11922398   \n",
       "6842       arthroscopy  12882611.tokens     0  12882611   \n",
       "7177           surgery  24532106.tokens     0  24532106   \n",
       "7250           surgery  21389925.tokens     0  21389925   \n",
       "7274           surgery  17618948.tokens     0  17618948   \n",
       "7717            biopsy  18837418.tokens     0  18837418   \n",
       "7880           surgery  25623276.tokens     0  25623276   \n",
       "\n",
       "                                     Spans  Surgical  Surgical Concord  \n",
       "13                      [), surgery, with]         1                 0  \n",
       "428                      [hip, surgery, .]         1                 0  \n",
       "1066  [severe, neuropsychiatric, toxicity]         1                 0  \n",
       "1954                  [(, ureteroscopy, )]         1                 0  \n",
       "3570          [gastric, endoscopy, scores]         1                 0  \n",
       "4036            [The, surgical, resection]         1                 0  \n",
       "5204            [the, surgical, procedure]         1                 0  \n",
       "6842        [requiring, arthroscopy, were]         1                 0  \n",
       "7177                  [before, surgery, .]         1                 0  \n",
       "7250                       [\", surgery, .]         1                 0  \n",
       "7274                   [after, surgery, ,]         1                 0  \n",
       "7717               [the, biopsy, specimen]         1                 0  \n",
       "7880     [colorectal, surgery, associated]         1                 0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "surg_discord = df_test[df_test[\"Surgical Concord\"] == 0]\n",
    "surg_discord = surg_discord[surg_discord[\"Surgical\"] != -1]\n",
    "display(surg_discord.head(100))\n",
    "display(surg_discord.tail(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5119499-afe8-44ba-9b79-2c09399e20a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
