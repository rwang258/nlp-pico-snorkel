{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffcb4bb9-12de-4189-85a3-3320ccf9be85",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data programming with Snorkel: Labeling the PICO dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e0a69cf-15ef-45ee-8861-bb873fce2904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importations.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import snorkel\n",
    "from snorkel.labeling import labeling_function\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling.model import MajorityLabelVoter\n",
    "from snorkel.labeling.model import LabelModel\n",
    "from snorkel.analysis import get_label_buckets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string # For punctuation.\n",
    "import os\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9baa17d-5e0c-4a07-b8a6-d52a309d24fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('first_sentence_file.pickle', 'rb') as handle:\n",
    "    first_sentence_file = pickle.load(handle)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73489cc0-4414-4ad9-ab40-ffd85d3f34ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Process keyword data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7dc43e5-51bc-4981-9ae5-083734b6a32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in suffixes.\n",
    "# https://druginfo.nlm.nih.gov/drugportal/jsp/drugportal/DrugNameGenericStems.jsp\n",
    "df_drugs = pd.read_csv(\"suffixes/drug_suffixes.txt\", header = None)\n",
    "df_surgery = pd.read_csv(\"suffixes/surgical_suffixes.txt\", header = None)\n",
    "df_psych = pd.read_csv(\"suffixes/psychotherapy_keywords.txt\", header = None)\n",
    "\n",
    "df_psych[0] = df_psych[0].str.lower()\n",
    "df_surgery[0] = df_surgery[0].str.lower()\n",
    "df_drugs[0] = df_drugs[0].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14a4a89e-08f7-48c3-b318-d9b82dbed512",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 35225: expected 8 fields, saw 9\\nSkipping line 35226: expected 8 fields, saw 9\\nSkipping line 35227: expected 8 fields, saw 9\\n'\n"
     ]
    }
   ],
   "source": [
    "# Read in FDA data.\n",
    "\n",
    "df_purple = pd.read_csv(\"fda_approved_drugs/products_purplebook.csv\")\n",
    "df_orange = pd.read_csv(\"fda_approved_drugs/products_orangebook.txt\", \n",
    "                        sep = \"~\")\n",
    "df_drugs_at_fda = pd.read_csv(\"fda_approved_drugs/products_drugs_at_fda.txt\", \n",
    "                              sep = \"\\t\", \n",
    "                              error_bad_lines = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d65cb622-487c-4872-ab25-87399bfd84b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter drug suffixes with three characters or fewer.\n",
    "drug_suffixes = list(df_drugs[0])\n",
    "drug_suffixes = [x.lower() for x in drug_suffixes if len(x) > 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73432812-6063-449f-bfbd-2e8756a4b0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate FDA drug data.\n",
    "set_proprietary = list(df_drugs_at_fda[\"DrugName\"]) + list(df_purple[\"Proprietary Name\"]) + list(df_orange[\"Trade_Name\"])\n",
    "set_proper = list(df_drugs_at_fda[\"ActiveIngredient\"]) + list(df_purple[\"Proper Name\"]) + list(df_orange[\"Ingredient\"])\n",
    "\n",
    "# Remove floats and integers.\n",
    "set_proprietary = [item.lower() for item in set_proprietary if not isinstance(item, float)]\n",
    "set_proprietary = [item for item in set_proprietary if not isinstance(item, int)]\n",
    "set_proper = [item.lower() for item in set_proper if not isinstance(item, float)]\n",
    "set_proper = [item for item in set_proper if not isinstance(item, int)]\n",
    "\n",
    "# Cast as sets to remove duplicates.\n",
    "set_proprietary = set(set_proprietary)\n",
    "set_proper = set(set_proper)\n",
    "set_fda = set.union(set_proprietary, set_proper)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2442c7-c67d-4929-99aa-45f5150a6141",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bcb22ea-dfc7-4bec-bfd3-89ecfe78f5b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_orig = pd.read_pickle('df_orig.pickle')\n",
    "\n",
    "\n",
    "# Train-test split (80% / 20%, stratified by gold label value).\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_orig[\"Token\"], \n",
    "                                                    df_orig[\"Gold\"], \n",
    "                                                    test_size = 0.1, \n",
    "                                                    random_state = 42)\n",
    "df_train = df_orig.iloc[X_train.index].reset_index(drop = True)\n",
    "df_test = df_orig.iloc[X_test.index].reset_index(drop = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ff733a5-7169-4653-816c-c90df8b4eeef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1770        cm\n",
       "1888         P\n",
       "6951         2\n",
       "1642         a\n",
       "7425        to\n",
       "         ...  \n",
       "5734     Heart\n",
       "5191      with\n",
       "5390       The\n",
       "860     solute\n",
       "7270         p\n",
       "Name: Token, Length: 8016, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91caec48-6839-4e1f-b32a-4bcf63765253",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Labeling functions\n",
    "\n",
    "Labeling functions will be written to cover the following intervention categories, as used by the manual annotators of this [dataset](https://github.com/bepnye/EBM-NLP):\n",
    "\n",
    "- Surgical.\n",
    "- Physical.\n",
    "- Drug.\n",
    "- Educational.\n",
    "- Psychological.\n",
    "- Other.\n",
    "- Control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c681538f-de23-409a-a9fd-311493e99fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stop words = 179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/rcw258/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Label macros.\n",
    "ABSTAIN = -1\n",
    "NOT_I = 0\n",
    "I = 1\n",
    "\n",
    "# Data for labeling functions.\n",
    "generic_interventions = [\"therap\", \"treatment\", \"intervention\",\n",
    "                         \"placebo\", \"dose\", \"control\", \"vaccin\"]\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = stopwords.words(\"english\")\n",
    "print(\"Total stop words =\", len(stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913a3071-c24f-4336-9192-65f1ab5dfe9a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Labeling functions\n",
    "**All labeling functions label tokens. The corresponding gold labels are from the \"starting span\" labels.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b3292de-a337-4cf2-9976-629fafae9335",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labeling_function' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2498c09286d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Labeling function for tokens, if token is present in first sentence (title)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mlabeling_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresources\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_sentence_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfirst_sentence_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0min_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_sentence_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mI\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfirst_sentence_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mABSTAIN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# abstain or not_i?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labeling_function' is not defined"
     ]
    }
   ],
   "source": [
    "# Labeling function for tokens, if token is present in first sentence (title)\n",
    "@labeling_function(resources=dict(first_sentence_file=first_sentence_file))\n",
    "def in_title(x, first_sentence_file):\n",
    "    return I if x.Token.lower() in first_sentence_file[x.File] else ABSTAIN\n",
    "# abstain or not_i?\n",
    "\n",
    "# Labeling function for tokens, if token is present in first sentence (title)\n",
    "@labeling_function(resources=dict(first_sentence_file=first_sentence_file))\n",
    "def in_title2(x, first_sentence_file):\n",
    "    return I if x.Token.lower() in first_sentence_file[x.File] else ABSTAIN\n",
    "# abstain or not_i?\n",
    "\n",
    "# Labeling function for tokens, if token is present in first sentence (title)\n",
    "@labeling_function(resources=dict(first_sentence_file=first_sentence_file))\n",
    "def in_title3(x, first_sentence_file):\n",
    "    return I if x.Token.lower() in first_sentence_file[x.File] else ABSTAIN\n",
    "# abstain or not_i?\n",
    "\n",
    "# Labeling function for tokens, if token is present in first sentence (title)\n",
    "@labeling_function(resources=dict(first_sentence_file=first_sentence_file))\n",
    "def in_title4(x, first_sentence_file):\n",
    "    return I if x.Token.lower() in first_sentence_file[x.File] else ABSTAIN\n",
    "# abstain or not_i?\n",
    "\n",
    "\n",
    "# Labeling function for tokens, if token is present in first sentence (title)\n",
    "@labeling_function(resources=dict(first_sentence_file=first_sentence_file))\n",
    "def not_in_title(x, first_sentence_file):\n",
    "    return NOT_I if x.Token.lower() not in first_sentence_file[x.File] else ABSTAIN\n",
    "# abstain or not_i?\n",
    "\n",
    "\n",
    "@labeling_function(resources=dict(first_sentence_file=first_sentence_file))\n",
    "def surround_in_title(x, first_sentence_file):\n",
    "    if((x.token_index>0) and (x.token_index<len(x.abstract)-1)):\n",
    "        if (x.abstract[x.token_index-1].lower() in first_sentence_file[x.File]) and (x.abstract[x.token_index+1].lower() in first_sentence_file[x.File]):\n",
    "            return I\n",
    "    \n",
    "    return ABSTAIN\n",
    "# abstain or not_i?\n",
    "\n",
    "\n",
    "# Labeling function for tokens that contain drug suffixes.\n",
    "@labeling_function()\n",
    "def contains_drug_suffix(x):\n",
    "    return I if (any(suffix.lower() in x.Token.lower() for suffix in drug_suffixes)) else ABSTAIN\n",
    "    \n",
    "# Labeling function for tokens that contain surgical suffixes.\n",
    "@labeling_function()\n",
    "def contains_surgical_suffix(x):\n",
    "    return I if (any(suffix.lower() in x.Token.lower() for suffix in df_surgery[0])) else ABSTAIN\n",
    "\n",
    "# Labeling function for tokens that contain psychological / psychotherapeutic keywords.\n",
    "@labeling_function()\n",
    "def contains_psych_term(x):\n",
    "    return I if (any(suffix.lower() in x.Token.lower() for suffix in df_psych[0])) else ABSTAIN\n",
    "\n",
    "# Labeling function for tokens that contain generic intervention keywords.\n",
    "@labeling_function()\n",
    "def is_generic(x):\n",
    "    return I if (any(term.lower() in x.Token.lower() for term in generic_interventions)) else ABSTAIN\n",
    "\n",
    "# Labeling function for stop words.\n",
    "@labeling_function()\n",
    "def is_stop_word(x):\n",
    "    return NOT_I if x.Token.lower() in stop_words else ABSTAIN\n",
    "\n",
    "# Labeling function for tokens that are punctuation.\n",
    "@labeling_function()\n",
    "def is_punctuation(x):\n",
    "    return NOT_I if x.Token.lower() in string.punctuation else ABSTAIN\n",
    "\n",
    "\n",
    "# Labeling function for FDA approved drugs.\n",
    "@labeling_function()\n",
    "def contains_fda_drug(x):\n",
    "    if (len(x.Token) <= 5):\n",
    "        return ABSTAIN\n",
    "\n",
    "    return I if (any(x.Token.lower() in drug.lower() for drug in set_fda)) else ABSTAIN\n",
    "\n",
    "\n",
    "# checks if the preceding token is 'of' or 'with' (effect of... I, treat with... I)\n",
    "@labeling_function()\n",
    "def has_prev_word_as(x):\n",
    "    words = ['of', 'with', 'receive', 'and']\n",
    "    if ((x.token_index > 0) and (x.abstract[x.token_index-1].lower() in words)):\n",
    "        return I \n",
    "\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "    \n",
    "# checks if the next token is 'group' or 'groups'\n",
    "@labeling_function()\n",
    "def has_next_word_as(x):\n",
    "    words = ['group', 'groups']\n",
    "    if ((x.token_index < len(x.abstract)-1) and (x.abstract[x.token_index+1].lower() in words)):\n",
    "        return NOT_I\n",
    "\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "    \n",
    "# Labeling function which labels a token as NOT_I if it is in the last 50% of the file tokens.\n",
    "@labeling_function()\n",
    "def has_high_idx(x):\n",
    "    percent = x.token_index / x.file_len\n",
    "    if percent > 0.50:\n",
    "        return NOT_I\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "    \n",
    "    \n",
    "    \n",
    "# Labeling function for tokens, sees if left span of token within sentence contains keyword\n",
    "@labeling_function()\n",
    "def left_span_contains(x):\n",
    "    \n",
    "    i = 0\n",
    "    while(x.abstract[i] != x.Token):\n",
    "        i+=1\n",
    "        \n",
    "    count = 0\n",
    "    while(i >= 0 and count < 10):\n",
    "        if((x.abstract[i] == 'determine') or (x.abstract[i] == 'assess')):\n",
    "            return I\n",
    "        i-=1\n",
    "        count+=1\n",
    "        \n",
    "    return ABSTAIN\n",
    "# look into spouse tutorial left spans, and using 'resources' in LFs\n",
    "\n",
    "\n",
    "# checks if the preceding token is VBD, VBN (e.g. was administered)\n",
    "@labeling_function()\n",
    "def right_span_vb_pos(x):\n",
    "    if (x.token_index < len(x.abstract) - 2) and (x.pos_abstract[x.tokem_index+1] == 'VBD') and (x.pos_abstract[x.token_index+2] == 'VBN'):\n",
    "        return I \n",
    "\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "    \n",
    "    \n",
    "# checks if the preceding token is VBD, VBN (e.g. was administered)\n",
    "@labeling_function()\n",
    "def left_span_vb_pos(x):\n",
    "    if (x.token_index > 0) and ('V' in x.pos_abstract[x.token_index-1]):\n",
    "        return I \n",
    "\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "    \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e186e6-5b55-42d8-a953-73acdb04e2bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Apply labeling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e06f424-1595-415c-ac59-e062efbf3789",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8016/8016 [03:01<00:00, 44.18it/s]\n",
      "100%|██████████| 2005/2005 [00:42<00:00, 46.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# Apply LFs to dataframe.\n",
    "lfs = [\n",
    "       #contains_psych_term, # accuracy = 0.131380\n",
    "       # is_punctuation,\n",
    "       #has_prev_word_as,\n",
    "    \n",
    "       # has_next_word_as_drug, low accuracy and coverage\n",
    "    \n",
    "       # left_span_contains,\n",
    "       # right_span_vb_pos,\n",
    "       # left_span_vb_pos,\n",
    "    \n",
    "       #negative LFs\n",
    "       is_stop_word,\n",
    "       has_next_word_as,\n",
    "       has_high_idx,\n",
    "    \n",
    "       #positive LFs\n",
    "       is_generic,\n",
    "       contains_drug_suffix,\n",
    "       contains_surgical_suffix,\n",
    "       contains_fda_drug,\n",
    "    \n",
    "       in_title,\n",
    "        in_title2,\n",
    "        in_title3,\n",
    "        in_title4,\n",
    "       # not_in_title,\n",
    "       surround_in_title,\n",
    "\n",
    "      ]\n",
    "applier = PandasLFApplier(lfs = lfs)\n",
    "L_train = applier.apply(df = df_train)\n",
    "L_test = applier.apply(df = df_test)\n",
    "# L_dev = applier.apply(df = df_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "601af81e-1583-4c1c-b8a8-39c21d30fbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#L_train\n",
    "# L_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "63b7fb58-3122-4040-913f-9c3c6f1455ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # %%capture\n",
    "\n",
    "# coverage_check_out, coverage_check = (L_dev != ABSTAIN).mean(axis = 0)\n",
    "# print(f\"check_out coverage: {coverage_check_out * 100:.1f}%\")\n",
    "# print(f\"check coverage: {coverage_check * 100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "2b7ac091-85e1-4b73-b200-98bf96af3ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#L_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c6ea8c7-e289-4499-81b7-524612418c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Y_train, Y_test.\n",
    "Y_train = df_train[\"Gold\"].to_numpy(dtype = int)\n",
    "Y_test = df_test[\"Gold\"].to_numpy(dtype = int)\n",
    "# Y_dev = df_dev[\"Gold\"].to_numpy(dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac65f849-308f-4444-a89a-c0a3324c7510",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/apps/anaconda3/2021.05/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/share/apps/anaconda3/2021.05/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/share/apps/anaconda3/2021.05/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/share/apps/anaconda3/2021.05/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/share/apps/anaconda3/2021.05/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/share/apps/anaconda3/2021.05/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/share/apps/anaconda3/2021.05/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/share/apps/anaconda3/2021.05/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/share/apps/anaconda3/2021.05/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/share/apps/anaconda3/2021.05/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/share/apps/anaconda3/2021.05/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/share/apps/anaconda3/2021.05/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_stop_word</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.272829</td>\n",
       "      <td>0.185629</td>\n",
       "      <td>0.086327</td>\n",
       "      <td>2097</td>\n",
       "      <td>90</td>\n",
       "      <td>0.958848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_next_word_as</th>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>0.004491</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>0.951220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_high_idx</th>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.495010</td>\n",
       "      <td>0.212700</td>\n",
       "      <td>0.112151</td>\n",
       "      <td>3813</td>\n",
       "      <td>155</td>\n",
       "      <td>0.960938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_generic</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.015220</td>\n",
       "      <td>0.011103</td>\n",
       "      <td>0.007735</td>\n",
       "      <td>41</td>\n",
       "      <td>81</td>\n",
       "      <td>0.336066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contains_drug_suffix</th>\n",
       "      <td>4</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.021956</td>\n",
       "      <td>0.015344</td>\n",
       "      <td>0.008733</td>\n",
       "      <td>60</td>\n",
       "      <td>116</td>\n",
       "      <td>0.340909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contains_surgical_suffix</th>\n",
       "      <td>5</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>0.002869</td>\n",
       "      <td>0.001497</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contains_fda_drug</th>\n",
       "      <td>6</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.044661</td>\n",
       "      <td>0.034681</td>\n",
       "      <td>0.020709</td>\n",
       "      <td>116</td>\n",
       "      <td>242</td>\n",
       "      <td>0.324022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_title</th>\n",
       "      <td>7</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.217690</td>\n",
       "      <td>0.217690</td>\n",
       "      <td>0.122505</td>\n",
       "      <td>252</td>\n",
       "      <td>1493</td>\n",
       "      <td>0.144413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_title2</th>\n",
       "      <td>8</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.217690</td>\n",
       "      <td>0.217690</td>\n",
       "      <td>0.122505</td>\n",
       "      <td>252</td>\n",
       "      <td>1493</td>\n",
       "      <td>0.144413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_title3</th>\n",
       "      <td>9</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.217690</td>\n",
       "      <td>0.217690</td>\n",
       "      <td>0.122505</td>\n",
       "      <td>252</td>\n",
       "      <td>1493</td>\n",
       "      <td>0.144413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_title4</th>\n",
       "      <td>10</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.217690</td>\n",
       "      <td>0.217690</td>\n",
       "      <td>0.122505</td>\n",
       "      <td>252</td>\n",
       "      <td>1493</td>\n",
       "      <td>0.144413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surround_in_title</th>\n",
       "      <td>11</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.089820</td>\n",
       "      <td>0.084830</td>\n",
       "      <td>0.037924</td>\n",
       "      <td>102</td>\n",
       "      <td>618</td>\n",
       "      <td>0.141667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           j Polarity  Coverage  Overlaps  Conflicts  Correct  \\\n",
       "is_stop_word               0      [0]  0.272829  0.185629   0.086327     2097   \n",
       "has_next_word_as           1      [0]  0.005115  0.004491   0.002121       39   \n",
       "has_high_idx               2      [0]  0.495010  0.212700   0.112151     3813   \n",
       "is_generic                 3      [1]  0.015220  0.011103   0.007735       41   \n",
       "contains_drug_suffix       4      [1]  0.021956  0.015344   0.008733       60   \n",
       "contains_surgical_suffix   5      [1]  0.002994  0.002869   0.001497        2   \n",
       "contains_fda_drug          6      [1]  0.044661  0.034681   0.020709      116   \n",
       "in_title                   7      [1]  0.217690  0.217690   0.122505      252   \n",
       "in_title2                  8      [1]  0.217690  0.217690   0.122505      252   \n",
       "in_title3                  9      [1]  0.217690  0.217690   0.122505      252   \n",
       "in_title4                 10      [1]  0.217690  0.217690   0.122505      252   \n",
       "surround_in_title         11      [1]  0.089820  0.084830   0.037924      102   \n",
       "\n",
       "                          Incorrect  Emp. Acc.  \n",
       "is_stop_word                     90   0.958848  \n",
       "has_next_word_as                  2   0.951220  \n",
       "has_high_idx                    155   0.960938  \n",
       "is_generic                       81   0.336066  \n",
       "contains_drug_suffix            116   0.340909  \n",
       "contains_surgical_suffix         22   0.083333  \n",
       "contains_fda_drug               242   0.324022  \n",
       "in_title                       1493   0.144413  \n",
       "in_title2                      1493   0.144413  \n",
       "in_title3                      1493   0.144413  \n",
       "in_title4                      1493   0.144413  \n",
       "surround_in_title               618   0.141667  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarive coverage, conflicts, empirical accurcacy of LFs.\n",
    "LFAnalysis(L_train, lfs).lf_summary(Y_train)\n",
    "# LFAnalysis(L_dev, lfs).lf_summary(Y_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65ba588d-1ae3-4208-a3e6-28aefdf2e54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/apps/anaconda3/2021.05/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/share/apps/anaconda3/2021.05/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/share/apps/anaconda3/2021.05/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/share/apps/anaconda3/2021.05/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/share/apps/anaconda3/2021.05/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/share/apps/anaconda3/2021.05/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/share/apps/anaconda3/2021.05/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/share/apps/anaconda3/2021.05/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/share/apps/anaconda3/2021.05/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/share/apps/anaconda3/2021.05/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/share/apps/anaconda3/2021.05/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/share/apps/anaconda3/2021.05/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=[-1  0  1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_stop_word</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.286284</td>\n",
       "      <td>0.203990</td>\n",
       "      <td>0.094763</td>\n",
       "      <td>539</td>\n",
       "      <td>35</td>\n",
       "      <td>0.939024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_next_word_as</th>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>0.002494</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_high_idx</th>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.505736</td>\n",
       "      <td>0.226434</td>\n",
       "      <td>0.116209</td>\n",
       "      <td>973</td>\n",
       "      <td>41</td>\n",
       "      <td>0.959566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_generic</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.017955</td>\n",
       "      <td>0.012968</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contains_drug_suffix</th>\n",
       "      <td>4</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.020948</td>\n",
       "      <td>0.014963</td>\n",
       "      <td>0.006983</td>\n",
       "      <td>13</td>\n",
       "      <td>29</td>\n",
       "      <td>0.309524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contains_surgical_suffix</th>\n",
       "      <td>5</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contains_fda_drug</th>\n",
       "      <td>6</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.045387</td>\n",
       "      <td>0.037905</td>\n",
       "      <td>0.021446</td>\n",
       "      <td>30</td>\n",
       "      <td>61</td>\n",
       "      <td>0.329670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_title</th>\n",
       "      <td>7</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.226434</td>\n",
       "      <td>0.226434</td>\n",
       "      <td>0.138155</td>\n",
       "      <td>62</td>\n",
       "      <td>392</td>\n",
       "      <td>0.136564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_title2</th>\n",
       "      <td>8</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.226434</td>\n",
       "      <td>0.226434</td>\n",
       "      <td>0.138155</td>\n",
       "      <td>62</td>\n",
       "      <td>392</td>\n",
       "      <td>0.136564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_title3</th>\n",
       "      <td>9</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.226434</td>\n",
       "      <td>0.226434</td>\n",
       "      <td>0.138155</td>\n",
       "      <td>62</td>\n",
       "      <td>392</td>\n",
       "      <td>0.136564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_title4</th>\n",
       "      <td>10</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.226434</td>\n",
       "      <td>0.226434</td>\n",
       "      <td>0.138155</td>\n",
       "      <td>62</td>\n",
       "      <td>392</td>\n",
       "      <td>0.136564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surround_in_title</th>\n",
       "      <td>11</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.097257</td>\n",
       "      <td>0.089277</td>\n",
       "      <td>0.040898</td>\n",
       "      <td>31</td>\n",
       "      <td>164</td>\n",
       "      <td>0.158974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           j Polarity  Coverage  Overlaps  Conflicts  Correct  \\\n",
       "is_stop_word               0      [0]  0.286284  0.203990   0.094763      539   \n",
       "has_next_word_as           1      [0]  0.002993  0.002494   0.001496        5   \n",
       "has_high_idx               2      [0]  0.505736  0.226434   0.116209      973   \n",
       "is_generic                 3      [1]  0.017955  0.012968   0.007481       15   \n",
       "contains_drug_suffix       4      [1]  0.020948  0.014963   0.006983       13   \n",
       "contains_surgical_suffix   5      [1]  0.001995  0.001995   0.000499        0   \n",
       "contains_fda_drug          6      [1]  0.045387  0.037905   0.021446       30   \n",
       "in_title                   7      [1]  0.226434  0.226434   0.138155       62   \n",
       "in_title2                  8      [1]  0.226434  0.226434   0.138155       62   \n",
       "in_title3                  9      [1]  0.226434  0.226434   0.138155       62   \n",
       "in_title4                 10      [1]  0.226434  0.226434   0.138155       62   \n",
       "surround_in_title         11      [1]  0.097257  0.089277   0.040898       31   \n",
       "\n",
       "                          Incorrect  Emp. Acc.  \n",
       "is_stop_word                     35   0.939024  \n",
       "has_next_word_as                  1   0.833333  \n",
       "has_high_idx                     41   0.959566  \n",
       "is_generic                       21   0.416667  \n",
       "contains_drug_suffix             29   0.309524  \n",
       "contains_surgical_suffix          4   0.000000  \n",
       "contains_fda_drug                61   0.329670  \n",
       "in_title                        392   0.136564  \n",
       "in_title2                       392   0.136564  \n",
       "in_title3                       392   0.136564  \n",
       "in_title4                       392   0.136564  \n",
       "surround_in_title               164   0.158974  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L_test, lfs).lf_summary(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6fa31de-c1ca-4661-a20d-e399b67fa264",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "'''\n",
    "# Explore buckets for patterns in discordance.\n",
    "buckets = get_label_buckets(L_train[:, 0], L_train[:, 1])\n",
    "display(buckets)\n",
    "display(df_train.iloc[buckets[(NOT_I, I)]].sample(10, random_state = 1))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08007c6b-893e-43da-81fa-c8e20261e226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Majority vote model.\n",
    "majority_model = MajorityLabelVoter()\n",
    "preds_train = majority_model.predict(L = L_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29029239-cbc5-460f-a5ce-476ac782e55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/500 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.746]\n",
      "  0%|          | 1/500 [00:00<01:28,  5.63epoch/s]INFO:root:[100 epochs]: TRAIN:[loss=0.001]\n",
      " 25%|██▌       | 127/500 [00:00<00:00, 564.38epoch/s]INFO:root:[200 epochs]: TRAIN:[loss=0.001]\n",
      " 53%|█████▎    | 265/500 [00:00<00:00, 879.52epoch/s]INFO:root:[300 epochs]: TRAIN:[loss=0.001]\n",
      "INFO:root:[400 epochs]: TRAIN:[loss=0.001]\n",
      "100%|██████████| 500/500 [00:00<00:00, 905.56epoch/s] \n",
      "INFO:root:Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Label model.\n",
    "label_model = LabelModel(cardinality = 2, verbose = True)\n",
    "label_model.fit(L_train = L_train, n_epochs = 500, log_freq = 100, seed = 123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98745ac8-e558-4350-aff7-beb7cedb758d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute model performance metrics.\n",
    "majority_scores = majority_model.score(L = L_test, Y = Y_test, \n",
    "                                       tie_break_policy = \"random\",\n",
    "                                       metrics = [\"f1\", \"accuracy\", \"precision\", \n",
    "                                                  \"recall\", \"roc_auc\", \"coverage\"])\n",
    "label_scores = label_model.score(L = L_test, Y = Y_test, \n",
    "                                 tie_break_policy = \"random\",\n",
    "                                 metrics = [\"f1\", \"accuracy\", \"precision\", \n",
    "                                            \"recall\", \"roc_auc\", \"coverage\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad7a6fb6-4119-4b0c-91a4-db1ce809f717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Model F1:        23.6%\n",
      "Majority Model Accuracy:  62.8%\n",
      "Majority Model Precision: 14.5%\n",
      "Majority Model Recall:    63.2%\n",
      "Majority Model AUC ROC:   65.7%\n",
      "Majority Model Coverage:  100.0%\n",
      "++++++++++++++++++++++++\n",
      "Label Model F1:           20.7%\n",
      "Label Model Accuracy:     45.2%\n",
      "Label Model Precision:    11.9%\n",
      "Label Model Recall:       78.6%\n",
      "Label Model AUC ROC:      64.6%\n",
      "Label Model Coverage:     100.0%\n"
     ]
    }
   ],
   "source": [
    "# Compare model performance metrics.\n",
    "majority_f1 = majority_scores.get(\"f1\")\n",
    "majority_acc = majority_scores.get(\"accuracy\")\n",
    "majority_prec = majority_scores.get(\"precision\")\n",
    "majority_rec = majority_scores.get(\"recall\")\n",
    "majority_roc = majority_scores.get(\"roc_auc\")\n",
    "majority_cov = majority_scores.get(\"coverage\")\n",
    "print(f\"{'Majority Model F1:':<25} {majority_f1 * 100:.1f}%\")\n",
    "print(f\"{'Majority Model Accuracy:':<25} {majority_acc * 100:.1f}%\")\n",
    "print(f\"{'Majority Model Precision:':<25} {majority_prec * 100:.1f}%\")\n",
    "print(f\"{'Majority Model Recall:':<25} {majority_rec * 100:.1f}%\")\n",
    "print(f\"{'Majority Model AUC ROC:':<25} {majority_roc * 100:.1f}%\")\n",
    "print(f\"{'Majority Model Coverage:':<25} {majority_cov * 100:.1f}%\")\n",
    "print(\"++++++++++++++++++++++++\")\n",
    "\n",
    "label_f1 = label_scores.get(\"f1\")\n",
    "label_acc = label_scores.get(\"accuracy\")\n",
    "label_prec = label_scores.get(\"precision\")\n",
    "label_rec = label_scores.get(\"recall\")\n",
    "label_roc = label_scores.get(\"roc_auc\")\n",
    "label_cov = label_scores.get(\"coverage\")\n",
    "print(f\"{'Label Model F1:':<25} {label_f1 * 100:.1f}%\")\n",
    "print(f\"{'Label Model Accuracy:':<25} {label_acc * 100:.1f}%\")\n",
    "print(f\"{'Label Model Precision:':<25} {label_prec * 100:.1f}%\")\n",
    "print(f\"{'Label Model Recall:':<25} {label_rec * 100:.1f}%\")\n",
    "print(f\"{'Label Model AUC ROC:':<25} {label_roc * 100:.1f}%\")\n",
    "print(f\"{'Label Model Coverage:':<25} {label_cov * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4c46638-9b8e-4937-8a8e-fd8878554835",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 24 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy if predicting majority class 0.9092269326683292\n"
     ]
    }
   ],
   "source": [
    "# View \"dummy\" accuracy if predicting majority class every time.\n",
    "print(\"Accuracy if predicting majority class\", \n",
    "      df_test[\"Gold\"].value_counts(normalize = True).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dad229-acdc-4be3-a5c1-660cb53d15e0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Explore errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "c694ab7d-3093-4fc5-8803-a5886f64d619",
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function(pre=[spacy])\n",
    "def is_noun(x):\n",
    "    if x.doc.pos[0] == 'noun':\n",
    "        return I\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "ae1dea8a-5ca7-4b8d-a0f9-a8e416b98101",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error = df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "3a14e093-8b28-411d-aeed-77b967a83e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>File</th>\n",
       "      <th>Gold</th>\n",
       "      <th>PMID</th>\n",
       "      <th>token_index</th>\n",
       "      <th>file_len</th>\n",
       "      <th>Spans</th>\n",
       "      <th>LF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.</td>\n",
       "      <td>20369616.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>20369616</td>\n",
       "      <td>120</td>\n",
       "      <td>121</td>\n",
       "      <td>[drug, ., Does]</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and</td>\n",
       "      <td>21410033.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>21410033</td>\n",
       "      <td>91</td>\n",
       "      <td>195</td>\n",
       "      <td>[total, and, conjugated]</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quality</td>\n",
       "      <td>15673894.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>15673894</td>\n",
       "      <td>25</td>\n",
       "      <td>308</td>\n",
       "      <td>[the, quality, of]</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>)</td>\n",
       "      <td>1631861.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>1631861</td>\n",
       "      <td>172</td>\n",
       "      <td>218</td>\n",
       "      <td>[9/14, ), .]</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on</td>\n",
       "      <td>20390261.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>20390261</td>\n",
       "      <td>278</td>\n",
       "      <td>293</td>\n",
       "      <td>[effect, on, reversal]</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Token             File Gold      PMID  token_index  file_len  \\\n",
       "0        .  20369616.tokens    0  20369616          120       121   \n",
       "1      and  21410033.tokens    0  21410033           91       195   \n",
       "2  quality  15673894.tokens    0  15673894           25       308   \n",
       "3        )   1631861.tokens    0   1631861          172       218   \n",
       "4       on  20390261.tokens    0  20390261          278       293   \n",
       "\n",
       "                      Spans  LF  \n",
       "0           [drug, ., Does]  -1  \n",
       "1  [total, and, conjugated]  -1  \n",
       "2        [the, quality, of]  -1  \n",
       "3              [9/14, ), .]  -1  \n",
       "4    [effect, on, reversal]  -1  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_error[\"LF\"] = df_error.apply(lambda x: has_next_word_as_drug(x), axis=1)\n",
    "df_error.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "84316461-649a-45fa-8d2c-66f2b1be17bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>File</th>\n",
       "      <th>Gold</th>\n",
       "      <th>PMID</th>\n",
       "      <th>token_index</th>\n",
       "      <th>file_len</th>\n",
       "      <th>Spans</th>\n",
       "      <th>LF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>fentanyl</td>\n",
       "      <td>21935685.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>21935685</td>\n",
       "      <td>147</td>\n",
       "      <td>209</td>\n",
       "      <td>[after, fentanyl, bolus]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>standardized</td>\n",
       "      <td>15264973.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>15264973</td>\n",
       "      <td>65</td>\n",
       "      <td>156</td>\n",
       "      <td>[in, standardized, body]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>anesthesia</td>\n",
       "      <td>18672629.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>18672629</td>\n",
       "      <td>72</td>\n",
       "      <td>265</td>\n",
       "      <td>[general, anesthesia, was]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>triple</td>\n",
       "      <td>24684165.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>24684165</td>\n",
       "      <td>198</td>\n",
       "      <td>337</td>\n",
       "      <td>[the, triple, combination]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>groups</td>\n",
       "      <td>24691455.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>24691455</td>\n",
       "      <td>92</td>\n",
       "      <td>214</td>\n",
       "      <td>[;, groups, B]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>groups</td>\n",
       "      <td>18453793.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>18453793</td>\n",
       "      <td>206</td>\n",
       "      <td>208</td>\n",
       "      <td>[patient, groups, .]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>papillomavirus</td>\n",
       "      <td>17367324.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>17367324</td>\n",
       "      <td>83</td>\n",
       "      <td>283</td>\n",
       "      <td>[human, papillomavirus, infection]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>infant</td>\n",
       "      <td>1741218.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>1741218</td>\n",
       "      <td>221</td>\n",
       "      <td>307</td>\n",
       "      <td>[natural, infant, suckling]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>venous</td>\n",
       "      <td>7211918.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>7211918</td>\n",
       "      <td>12</td>\n",
       "      <td>239</td>\n",
       "      <td>[deep, venous, thrombosis]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>cellular</td>\n",
       "      <td>10607234.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>10607234</td>\n",
       "      <td>404</td>\n",
       "      <td>448</td>\n",
       "      <td>[on, cellular, distribution]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>groups</td>\n",
       "      <td>15960148.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>15960148</td>\n",
       "      <td>250</td>\n",
       "      <td>436</td>\n",
       "      <td>[treatment, groups, pre-randomization]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>groups</td>\n",
       "      <td>9700583.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>9700583</td>\n",
       "      <td>303</td>\n",
       "      <td>437</td>\n",
       "      <td>[both, groups, ,]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>active</td>\n",
       "      <td>7032533.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>7032533</td>\n",
       "      <td>138</td>\n",
       "      <td>318</td>\n",
       "      <td>[the, active, drug]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>reduce</td>\n",
       "      <td>12614412.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>12614412</td>\n",
       "      <td>260</td>\n",
       "      <td>277</td>\n",
       "      <td>[to, reduce, the]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>solution</td>\n",
       "      <td>9587285.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>9587285</td>\n",
       "      <td>140</td>\n",
       "      <td>157</td>\n",
       "      <td>[each, solution, .]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>plasma</td>\n",
       "      <td>22129897.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>22129897</td>\n",
       "      <td>174</td>\n",
       "      <td>234</td>\n",
       "      <td>[in, plasma, sulfate]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>nicotine</td>\n",
       "      <td>25542917.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>25542917</td>\n",
       "      <td>274</td>\n",
       "      <td>301</td>\n",
       "      <td>[with, nicotine, exposure]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>recombinant</td>\n",
       "      <td>7635420.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>7635420</td>\n",
       "      <td>153</td>\n",
       "      <td>323</td>\n",
       "      <td>[,, recombinant, IL-2]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>sodium</td>\n",
       "      <td>23535873.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>23535873</td>\n",
       "      <td>205</td>\n",
       "      <td>303</td>\n",
       "      <td>[of, sodium, bicarbonate]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>kidney</td>\n",
       "      <td>15610252.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>15610252</td>\n",
       "      <td>187</td>\n",
       "      <td>296</td>\n",
       "      <td>[without, kidney, disease]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>single</td>\n",
       "      <td>25162407.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>25162407</td>\n",
       "      <td>293</td>\n",
       "      <td>395</td>\n",
       "      <td>[20-times, single, leg]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>groups</td>\n",
       "      <td>22324448.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>22324448</td>\n",
       "      <td>146</td>\n",
       "      <td>351</td>\n",
       "      <td>[two, groups, were]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>migraine</td>\n",
       "      <td>19570717.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>19570717</td>\n",
       "      <td>222</td>\n",
       "      <td>319</td>\n",
       "      <td>[median, migraine, headache]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>breath</td>\n",
       "      <td>10848655.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>10848655</td>\n",
       "      <td>153</td>\n",
       "      <td>414</td>\n",
       "      <td>[13C-urea, breath, test]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>prothrombin</td>\n",
       "      <td>375690.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>375690</td>\n",
       "      <td>135</td>\n",
       "      <td>192</td>\n",
       "      <td>[Plasma, prothrombin, and]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>activated</td>\n",
       "      <td>23205521.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>23205521</td>\n",
       "      <td>36</td>\n",
       "      <td>210</td>\n",
       "      <td>[experimentally, activated, self-face]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>reduced</td>\n",
       "      <td>23365106.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>23365106</td>\n",
       "      <td>156</td>\n",
       "      <td>395</td>\n",
       "      <td>[alone, reduced, (]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>headache</td>\n",
       "      <td>19570717.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>19570717</td>\n",
       "      <td>123</td>\n",
       "      <td>319</td>\n",
       "      <td>[of, headache, .]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>intravenous</td>\n",
       "      <td>25840597.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>25840597</td>\n",
       "      <td>216</td>\n",
       "      <td>250</td>\n",
       "      <td>[with, intravenous, bortezomib]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>groups</td>\n",
       "      <td>9513236.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>9513236</td>\n",
       "      <td>42</td>\n",
       "      <td>346</td>\n",
       "      <td>[surgery, groups, .]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>hepatitis</td>\n",
       "      <td>26166077.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>26166077</td>\n",
       "      <td>269</td>\n",
       "      <td>288</td>\n",
       "      <td>[chronic, hepatitis, B]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>reduction</td>\n",
       "      <td>1527133.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>1527133</td>\n",
       "      <td>100</td>\n",
       "      <td>156</td>\n",
       "      <td>[relative, reduction, of]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>fraction</td>\n",
       "      <td>8387067.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>8387067</td>\n",
       "      <td>227</td>\n",
       "      <td>271</td>\n",
       "      <td>[large, fraction, size]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372</th>\n",
       "      <td>length</td>\n",
       "      <td>8614420.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>8614420</td>\n",
       "      <td>98</td>\n",
       "      <td>276</td>\n",
       "      <td>[median, length, of]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <td>children</td>\n",
       "      <td>11535502.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>11535502</td>\n",
       "      <td>80</td>\n",
       "      <td>337</td>\n",
       "      <td>[younger, children, were]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>groups</td>\n",
       "      <td>24824660.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>24824660</td>\n",
       "      <td>238</td>\n",
       "      <td>309</td>\n",
       "      <td>[combining, groups, ,]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>children</td>\n",
       "      <td>21787048.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>21787048</td>\n",
       "      <td>404</td>\n",
       "      <td>413</td>\n",
       "      <td>[in, children, who]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>topical</td>\n",
       "      <td>12271298.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>12271298</td>\n",
       "      <td>20</td>\n",
       "      <td>206</td>\n",
       "      <td>[of, topical, anesthetics]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>aspirin</td>\n",
       "      <td>21996146.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>21996146</td>\n",
       "      <td>27</td>\n",
       "      <td>463</td>\n",
       "      <td>[of, aspirin, and]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>treated</td>\n",
       "      <td>23802768.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>23802768</td>\n",
       "      <td>94</td>\n",
       "      <td>275</td>\n",
       "      <td>[melanoma, treated, with]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>rapacuronium</td>\n",
       "      <td>10992833.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>10992833</td>\n",
       "      <td>192</td>\n",
       "      <td>316</td>\n",
       "      <td>[of, rapacuronium, was]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>standard</td>\n",
       "      <td>26040302.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>26040302</td>\n",
       "      <td>193</td>\n",
       "      <td>378</td>\n",
       "      <td>[±, standard, error]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>against</td>\n",
       "      <td>17388667.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>17388667</td>\n",
       "      <td>94</td>\n",
       "      <td>727</td>\n",
       "      <td>[protect, against, prostate]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956</th>\n",
       "      <td>secretin</td>\n",
       "      <td>20337981.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>20337981</td>\n",
       "      <td>230</td>\n",
       "      <td>274</td>\n",
       "      <td>[in, secretin, level]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>groups</td>\n",
       "      <td>20537413.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>20537413</td>\n",
       "      <td>157</td>\n",
       "      <td>208</td>\n",
       "      <td>[Both, groups, improved]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>rating</td>\n",
       "      <td>24345834.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>24345834</td>\n",
       "      <td>258</td>\n",
       "      <td>313</td>\n",
       "      <td>[average, rating, of]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>factor</td>\n",
       "      <td>11154142.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>11154142</td>\n",
       "      <td>87</td>\n",
       "      <td>245</td>\n",
       "      <td>[total, factor, VII]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>tracheal</td>\n",
       "      <td>22585469.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>22585469</td>\n",
       "      <td>47</td>\n",
       "      <td>338</td>\n",
       "      <td>[comparable, tracheal, intubation]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>complete</td>\n",
       "      <td>20008622.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>20008622</td>\n",
       "      <td>136</td>\n",
       "      <td>328</td>\n",
       "      <td>[and, complete, cytogenetic]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2183</th>\n",
       "      <td>groups</td>\n",
       "      <td>12459663.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>12459663</td>\n",
       "      <td>320</td>\n",
       "      <td>379</td>\n",
       "      <td>[three, groups, with]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Token             File Gold      PMID  token_index  file_len  \\\n",
       "54          fentanyl  21935685.tokens    0  21935685          147       209   \n",
       "125     standardized  15264973.tokens    0  15264973           65       156   \n",
       "183       anesthesia  18672629.tokens    0  18672629           72       265   \n",
       "236           triple  24684165.tokens    0  24684165          198       337   \n",
       "288           groups  24691455.tokens    0  24691455           92       214   \n",
       "314           groups  18453793.tokens    0  18453793          206       208   \n",
       "353   papillomavirus  17367324.tokens    0  17367324           83       283   \n",
       "408           infant   1741218.tokens    0   1741218          221       307   \n",
       "459           venous   7211918.tokens    0   7211918           12       239   \n",
       "464         cellular  10607234.tokens    0  10607234          404       448   \n",
       "552           groups  15960148.tokens    0  15960148          250       436   \n",
       "604           groups   9700583.tokens    0   9700583          303       437   \n",
       "634           active   7032533.tokens    0   7032533          138       318   \n",
       "727           reduce  12614412.tokens    0  12614412          260       277   \n",
       "735         solution   9587285.tokens    0   9587285          140       157   \n",
       "792           plasma  22129897.tokens    0  22129897          174       234   \n",
       "875         nicotine  25542917.tokens    0  25542917          274       301   \n",
       "876      recombinant   7635420.tokens    0   7635420          153       323   \n",
       "905           sodium  23535873.tokens    0  23535873          205       303   \n",
       "963           kidney  15610252.tokens    0  15610252          187       296   \n",
       "1097          single  25162407.tokens    0  25162407          293       395   \n",
       "1109          groups  22324448.tokens    0  22324448          146       351   \n",
       "1179        migraine  19570717.tokens    0  19570717          222       319   \n",
       "1193          breath  10848655.tokens    0  10848655          153       414   \n",
       "1253     prothrombin    375690.tokens    0    375690          135       192   \n",
       "1254       activated  23205521.tokens    0  23205521           36       210   \n",
       "1261         reduced  23365106.tokens    0  23365106          156       395   \n",
       "1288        headache  19570717.tokens    0  19570717          123       319   \n",
       "1298     intravenous  25840597.tokens    0  25840597          216       250   \n",
       "1306          groups   9513236.tokens    0   9513236           42       346   \n",
       "1325       hepatitis  26166077.tokens    0  26166077          269       288   \n",
       "1331       reduction   1527133.tokens    0   1527133          100       156   \n",
       "1337        fraction   8387067.tokens    0   8387067          227       271   \n",
       "1372          length   8614420.tokens    0   8614420           98       276   \n",
       "1380        children  11535502.tokens    0  11535502           80       337   \n",
       "1389          groups  24824660.tokens    0  24824660          238       309   \n",
       "1413        children  21787048.tokens    0  21787048          404       413   \n",
       "1418         topical  12271298.tokens    0  12271298           20       206   \n",
       "1494         aspirin  21996146.tokens    0  21996146           27       463   \n",
       "1557         treated  23802768.tokens    0  23802768           94       275   \n",
       "1631    rapacuronium  10992833.tokens    0  10992833          192       316   \n",
       "1723        standard  26040302.tokens    0  26040302          193       378   \n",
       "1795         against  17388667.tokens    0  17388667           94       727   \n",
       "1956        secretin  20337981.tokens    0  20337981          230       274   \n",
       "1994          groups  20537413.tokens    0  20537413          157       208   \n",
       "2009          rating  24345834.tokens    0  24345834          258       313   \n",
       "2014          factor  11154142.tokens    0  11154142           87       245   \n",
       "2131        tracheal  22585469.tokens    0  22585469           47       338   \n",
       "2144        complete  20008622.tokens    0  20008622          136       328   \n",
       "2183          groups  12459663.tokens    0  12459663          320       379   \n",
       "\n",
       "                                       Spans  LF  \n",
       "54                  [after, fentanyl, bolus]   1  \n",
       "125                 [in, standardized, body]   1  \n",
       "183               [general, anesthesia, was]   1  \n",
       "236               [the, triple, combination]   1  \n",
       "288                           [;, groups, B]   1  \n",
       "314                     [patient, groups, .]   1  \n",
       "353       [human, papillomavirus, infection]   1  \n",
       "408              [natural, infant, suckling]   1  \n",
       "459               [deep, venous, thrombosis]   1  \n",
       "464             [on, cellular, distribution]   1  \n",
       "552   [treatment, groups, pre-randomization]   1  \n",
       "604                        [both, groups, ,]   1  \n",
       "634                      [the, active, drug]   1  \n",
       "727                        [to, reduce, the]   1  \n",
       "735                      [each, solution, .]   1  \n",
       "792                    [in, plasma, sulfate]   1  \n",
       "875               [with, nicotine, exposure]   1  \n",
       "876                   [,, recombinant, IL-2]   1  \n",
       "905                [of, sodium, bicarbonate]   1  \n",
       "963               [without, kidney, disease]   1  \n",
       "1097                 [20-times, single, leg]   1  \n",
       "1109                     [two, groups, were]   1  \n",
       "1179            [median, migraine, headache]   1  \n",
       "1193                [13C-urea, breath, test]   1  \n",
       "1253              [Plasma, prothrombin, and]   1  \n",
       "1254  [experimentally, activated, self-face]   1  \n",
       "1261                     [alone, reduced, (]   1  \n",
       "1288                       [of, headache, .]   1  \n",
       "1298         [with, intravenous, bortezomib]   1  \n",
       "1306                    [surgery, groups, .]   1  \n",
       "1325                 [chronic, hepatitis, B]   1  \n",
       "1331               [relative, reduction, of]   1  \n",
       "1337                 [large, fraction, size]   1  \n",
       "1372                    [median, length, of]   1  \n",
       "1380               [younger, children, were]   1  \n",
       "1389                  [combining, groups, ,]   1  \n",
       "1413                     [in, children, who]   1  \n",
       "1418              [of, topical, anesthetics]   1  \n",
       "1494                      [of, aspirin, and]   1  \n",
       "1557               [melanoma, treated, with]   1  \n",
       "1631                 [of, rapacuronium, was]   1  \n",
       "1723                    [±, standard, error]   1  \n",
       "1795            [protect, against, prostate]   1  \n",
       "1956                   [in, secretin, level]   1  \n",
       "1994                [Both, groups, improved]   1  \n",
       "2009                   [average, rating, of]   1  \n",
       "2014                    [total, factor, VII]   1  \n",
       "2131      [comparable, tracheal, intubation]   1  \n",
       "2144            [and, complete, cytogenetic]   1  \n",
       "2183                   [three, groups, with]   1  "
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel = (df_error.LF == 1) & (df_error.Gold == '0') \n",
    "# labeled as NOT_I when actually I => 0 instances\n",
    "# labeled as I when actually NOT_I => non-zero\n",
    "df_error[sel].head(50)\n",
    "# df_orig[(df_orig.PMID=='3385217') & (df_orig.Gold=='1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef63637-5f9c-4641-af97-5a0a9dd2fc03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>File</th>\n",
       "      <th>Gold</th>\n",
       "      <th>PMID</th>\n",
       "      <th>token_index</th>\n",
       "      <th>file_len</th>\n",
       "      <th>Spans</th>\n",
       "      <th>Surgical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>surgery</td>\n",
       "      <td>19092729.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>19092729</td>\n",
       "      <td>17</td>\n",
       "      <td>332</td>\n",
       "      <td>[buckling, surgery, .]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>surgery</td>\n",
       "      <td>24532106.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>24532106</td>\n",
       "      <td>219</td>\n",
       "      <td>280</td>\n",
       "      <td>[after, surgery, ,]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>surgery</td>\n",
       "      <td>15616772.tokens</td>\n",
       "      <td>1</td>\n",
       "      <td>15616772</td>\n",
       "      <td>147</td>\n",
       "      <td>336</td>\n",
       "      <td>[(, surgery, only]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110</th>\n",
       "      <td>surgery</td>\n",
       "      <td>10078673.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>10078673</td>\n",
       "      <td>62</td>\n",
       "      <td>291</td>\n",
       "      <td>[abdominal, surgery, were]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141</th>\n",
       "      <td>surgery</td>\n",
       "      <td>9278836.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>9278836</td>\n",
       "      <td>254</td>\n",
       "      <td>434</td>\n",
       "      <td>[of, surgery, .]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3172</th>\n",
       "      <td>surgery</td>\n",
       "      <td>9278836.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>9278836</td>\n",
       "      <td>266</td>\n",
       "      <td>434</td>\n",
       "      <td>[of, surgery, ,]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5358</th>\n",
       "      <td>surgery</td>\n",
       "      <td>8604728.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>8604728</td>\n",
       "      <td>170</td>\n",
       "      <td>316</td>\n",
       "      <td>[filtering, surgery, group]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5837</th>\n",
       "      <td>surgery</td>\n",
       "      <td>14567804.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>14567804</td>\n",
       "      <td>86</td>\n",
       "      <td>240</td>\n",
       "      <td>[Before, surgery, ,]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7105</th>\n",
       "      <td>surgery</td>\n",
       "      <td>18779477.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>18779477</td>\n",
       "      <td>202</td>\n",
       "      <td>310</td>\n",
       "      <td>[glaucoma, surgery, was]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7944</th>\n",
       "      <td>surgery</td>\n",
       "      <td>11214014.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>11214014</td>\n",
       "      <td>12</td>\n",
       "      <td>306</td>\n",
       "      <td>[bypass, surgery, .]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7945</th>\n",
       "      <td>surgery</td>\n",
       "      <td>8823584.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>8823584</td>\n",
       "      <td>356</td>\n",
       "      <td>358</td>\n",
       "      <td>[segment, surgery, .]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8319</th>\n",
       "      <td>surgery</td>\n",
       "      <td>8367775.tokens</td>\n",
       "      <td>1</td>\n",
       "      <td>8367775</td>\n",
       "      <td>82</td>\n",
       "      <td>323</td>\n",
       "      <td>[spinal, surgery, .]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8858</th>\n",
       "      <td>surgery</td>\n",
       "      <td>9572066.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>9572066</td>\n",
       "      <td>329</td>\n",
       "      <td>364</td>\n",
       "      <td>[cardiac, surgery, .]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9928</th>\n",
       "      <td>surgery</td>\n",
       "      <td>12049860.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>12049860</td>\n",
       "      <td>92</td>\n",
       "      <td>285</td>\n",
       "      <td>[hip-replacement, surgery, to]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Token             File Gold      PMID  token_index  file_len  \\\n",
       "250   surgery  19092729.tokens    0  19092729           17       332   \n",
       "834   surgery  24532106.tokens    0  24532106          219       280   \n",
       "1130  surgery  15616772.tokens    1  15616772          147       336   \n",
       "2110  surgery  10078673.tokens    0  10078673           62       291   \n",
       "3141  surgery   9278836.tokens    0   9278836          254       434   \n",
       "3172  surgery   9278836.tokens    0   9278836          266       434   \n",
       "5358  surgery   8604728.tokens    0   8604728          170       316   \n",
       "5837  surgery  14567804.tokens    0  14567804           86       240   \n",
       "7105  surgery  18779477.tokens    0  18779477          202       310   \n",
       "7944  surgery  11214014.tokens    0  11214014           12       306   \n",
       "7945  surgery   8823584.tokens    0   8823584          356       358   \n",
       "8319  surgery   8367775.tokens    1   8367775           82       323   \n",
       "8858  surgery   9572066.tokens    0   9572066          329       364   \n",
       "9928  surgery  12049860.tokens    0  12049860           92       285   \n",
       "\n",
       "                               Spans  Surgical  \n",
       "250           [buckling, surgery, .]         1  \n",
       "834              [after, surgery, ,]         1  \n",
       "1130              [(, surgery, only]         1  \n",
       "2110      [abdominal, surgery, were]         1  \n",
       "3141                [of, surgery, .]         1  \n",
       "3172                [of, surgery, ,]         1  \n",
       "5358     [filtering, surgery, group]         1  \n",
       "5837            [Before, surgery, ,]         1  \n",
       "7105        [glaucoma, surgery, was]         1  \n",
       "7944            [bypass, surgery, .]         1  \n",
       "7945           [segment, surgery, .]         1  \n",
       "8319            [spinal, surgery, .]         1  \n",
       "8858           [cardiac, surgery, .]         1  \n",
       "9928  [hip-replacement, surgery, to]         1  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test.Token == 'surgery']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f2ca6be2-0c9e-459e-b8db-c2044bb2c084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>File</th>\n",
       "      <th>Gold</th>\n",
       "      <th>PMID</th>\n",
       "      <th>Spans</th>\n",
       "      <th>Surgical</th>\n",
       "      <th>Surgical Concord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>was</td>\n",
       "      <td>7562882.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>7562882</td>\n",
       "      <td>[lisinopril, was, observed]</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mortality</td>\n",
       "      <td>3139179.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>3139179</td>\n",
       "      <td>[RESULTS, Mortality, from]</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.</td>\n",
       "      <td>24077211.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>24077211</td>\n",
       "      <td>[trial, ., OBJECTIVE]</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>compared</td>\n",
       "      <td>10356632.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>10356632</td>\n",
       "      <td>[and, compared, to]</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>25542620.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>25542620</td>\n",
       "      <td>[:, a, randomised]</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Token             File  Gold      PMID                        Spans  \\\n",
       "0        was   7562882.tokens     0   7562882  [lisinopril, was, observed]   \n",
       "1  Mortality   3139179.tokens     0   3139179   [RESULTS, Mortality, from]   \n",
       "2          .  24077211.tokens     0  24077211        [trial, ., OBJECTIVE]   \n",
       "3   compared  10356632.tokens     0  10356632          [and, compared, to]   \n",
       "4          a  25542620.tokens     0  25542620           [:, a, randomised]   \n",
       "\n",
       "   Surgical  Surgical Concord  \n",
       "0        -1                 0  \n",
       "1        -1                 0  \n",
       "2        -1                 0  \n",
       "3        -1                 0  \n",
       "4        -1                 0  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"Gold\"] = df_test[\"Gold\"].astype(int)\n",
    "df_test[\"Surgical Concord\"] = np.where((df_test[\"Gold\"] == df_test[\"Surgical\"]), 1, 0)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6557c906-7c1a-454f-84f5-7b0b72037ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>File</th>\n",
       "      <th>Gold</th>\n",
       "      <th>PMID</th>\n",
       "      <th>Spans</th>\n",
       "      <th>Surgical</th>\n",
       "      <th>Surgical Concord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>surgery</td>\n",
       "      <td>7956382.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>7956382</td>\n",
       "      <td>[), surgery, with]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>surgery</td>\n",
       "      <td>1670445.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>1670445</td>\n",
       "      <td>[hip, surgery, .]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>neuropsychiatric</td>\n",
       "      <td>17513813.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>17513813</td>\n",
       "      <td>[severe, neuropsychiatric, toxicity]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>ureteroscopy</td>\n",
       "      <td>17156222.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>17156222</td>\n",
       "      <td>[(, ureteroscopy, )]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3570</th>\n",
       "      <td>endoscopy</td>\n",
       "      <td>12233894.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>12233894</td>\n",
       "      <td>[gastric, endoscopy, scores]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4036</th>\n",
       "      <td>surgical</td>\n",
       "      <td>15523393.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>15523393</td>\n",
       "      <td>[The, surgical, resection]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204</th>\n",
       "      <td>surgical</td>\n",
       "      <td>11922398.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>11922398</td>\n",
       "      <td>[the, surgical, procedure]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6842</th>\n",
       "      <td>arthroscopy</td>\n",
       "      <td>12882611.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>12882611</td>\n",
       "      <td>[requiring, arthroscopy, were]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7177</th>\n",
       "      <td>surgery</td>\n",
       "      <td>24532106.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>24532106</td>\n",
       "      <td>[before, surgery, .]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7250</th>\n",
       "      <td>surgery</td>\n",
       "      <td>21389925.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>21389925</td>\n",
       "      <td>[\", surgery, .]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7274</th>\n",
       "      <td>surgery</td>\n",
       "      <td>17618948.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>17618948</td>\n",
       "      <td>[after, surgery, ,]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7717</th>\n",
       "      <td>biopsy</td>\n",
       "      <td>18837418.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>18837418</td>\n",
       "      <td>[the, biopsy, specimen]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7880</th>\n",
       "      <td>surgery</td>\n",
       "      <td>25623276.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>25623276</td>\n",
       "      <td>[colorectal, surgery, associated]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Token             File  Gold      PMID  \\\n",
       "13             surgery   7956382.tokens     0   7956382   \n",
       "428            surgery   1670445.tokens     0   1670445   \n",
       "1066  neuropsychiatric  17513813.tokens     0  17513813   \n",
       "1954      ureteroscopy  17156222.tokens     0  17156222   \n",
       "3570         endoscopy  12233894.tokens     0  12233894   \n",
       "4036          surgical  15523393.tokens     0  15523393   \n",
       "5204          surgical  11922398.tokens     0  11922398   \n",
       "6842       arthroscopy  12882611.tokens     0  12882611   \n",
       "7177           surgery  24532106.tokens     0  24532106   \n",
       "7250           surgery  21389925.tokens     0  21389925   \n",
       "7274           surgery  17618948.tokens     0  17618948   \n",
       "7717            biopsy  18837418.tokens     0  18837418   \n",
       "7880           surgery  25623276.tokens     0  25623276   \n",
       "\n",
       "                                     Spans  Surgical  Surgical Concord  \n",
       "13                      [), surgery, with]         1                 0  \n",
       "428                      [hip, surgery, .]         1                 0  \n",
       "1066  [severe, neuropsychiatric, toxicity]         1                 0  \n",
       "1954                  [(, ureteroscopy, )]         1                 0  \n",
       "3570          [gastric, endoscopy, scores]         1                 0  \n",
       "4036            [The, surgical, resection]         1                 0  \n",
       "5204            [the, surgical, procedure]         1                 0  \n",
       "6842        [requiring, arthroscopy, were]         1                 0  \n",
       "7177                  [before, surgery, .]         1                 0  \n",
       "7250                       [\", surgery, .]         1                 0  \n",
       "7274                   [after, surgery, ,]         1                 0  \n",
       "7717               [the, biopsy, specimen]         1                 0  \n",
       "7880     [colorectal, surgery, associated]         1                 0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>File</th>\n",
       "      <th>Gold</th>\n",
       "      <th>PMID</th>\n",
       "      <th>Spans</th>\n",
       "      <th>Surgical</th>\n",
       "      <th>Surgical Concord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>surgery</td>\n",
       "      <td>7956382.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>7956382</td>\n",
       "      <td>[), surgery, with]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>surgery</td>\n",
       "      <td>1670445.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>1670445</td>\n",
       "      <td>[hip, surgery, .]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>neuropsychiatric</td>\n",
       "      <td>17513813.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>17513813</td>\n",
       "      <td>[severe, neuropsychiatric, toxicity]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>ureteroscopy</td>\n",
       "      <td>17156222.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>17156222</td>\n",
       "      <td>[(, ureteroscopy, )]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3570</th>\n",
       "      <td>endoscopy</td>\n",
       "      <td>12233894.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>12233894</td>\n",
       "      <td>[gastric, endoscopy, scores]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4036</th>\n",
       "      <td>surgical</td>\n",
       "      <td>15523393.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>15523393</td>\n",
       "      <td>[The, surgical, resection]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204</th>\n",
       "      <td>surgical</td>\n",
       "      <td>11922398.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>11922398</td>\n",
       "      <td>[the, surgical, procedure]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6842</th>\n",
       "      <td>arthroscopy</td>\n",
       "      <td>12882611.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>12882611</td>\n",
       "      <td>[requiring, arthroscopy, were]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7177</th>\n",
       "      <td>surgery</td>\n",
       "      <td>24532106.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>24532106</td>\n",
       "      <td>[before, surgery, .]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7250</th>\n",
       "      <td>surgery</td>\n",
       "      <td>21389925.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>21389925</td>\n",
       "      <td>[\", surgery, .]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7274</th>\n",
       "      <td>surgery</td>\n",
       "      <td>17618948.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>17618948</td>\n",
       "      <td>[after, surgery, ,]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7717</th>\n",
       "      <td>biopsy</td>\n",
       "      <td>18837418.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>18837418</td>\n",
       "      <td>[the, biopsy, specimen]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7880</th>\n",
       "      <td>surgery</td>\n",
       "      <td>25623276.tokens</td>\n",
       "      <td>0</td>\n",
       "      <td>25623276</td>\n",
       "      <td>[colorectal, surgery, associated]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Token             File  Gold      PMID  \\\n",
       "13             surgery   7956382.tokens     0   7956382   \n",
       "428            surgery   1670445.tokens     0   1670445   \n",
       "1066  neuropsychiatric  17513813.tokens     0  17513813   \n",
       "1954      ureteroscopy  17156222.tokens     0  17156222   \n",
       "3570         endoscopy  12233894.tokens     0  12233894   \n",
       "4036          surgical  15523393.tokens     0  15523393   \n",
       "5204          surgical  11922398.tokens     0  11922398   \n",
       "6842       arthroscopy  12882611.tokens     0  12882611   \n",
       "7177           surgery  24532106.tokens     0  24532106   \n",
       "7250           surgery  21389925.tokens     0  21389925   \n",
       "7274           surgery  17618948.tokens     0  17618948   \n",
       "7717            biopsy  18837418.tokens     0  18837418   \n",
       "7880           surgery  25623276.tokens     0  25623276   \n",
       "\n",
       "                                     Spans  Surgical  Surgical Concord  \n",
       "13                      [), surgery, with]         1                 0  \n",
       "428                      [hip, surgery, .]         1                 0  \n",
       "1066  [severe, neuropsychiatric, toxicity]         1                 0  \n",
       "1954                  [(, ureteroscopy, )]         1                 0  \n",
       "3570          [gastric, endoscopy, scores]         1                 0  \n",
       "4036            [The, surgical, resection]         1                 0  \n",
       "5204            [the, surgical, procedure]         1                 0  \n",
       "6842        [requiring, arthroscopy, were]         1                 0  \n",
       "7177                  [before, surgery, .]         1                 0  \n",
       "7250                       [\", surgery, .]         1                 0  \n",
       "7274                   [after, surgery, ,]         1                 0  \n",
       "7717               [the, biopsy, specimen]         1                 0  \n",
       "7880     [colorectal, surgery, associated]         1                 0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "surg_discord = df_test[df_test[\"Surgical Concord\"] == 0]\n",
    "surg_discord = surg_discord[surg_discord[\"Surgical\"] != -1]\n",
    "display(surg_discord.head(100))\n",
    "display(surg_discord.tail(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5119499-afe8-44ba-9b79-2c09399e20a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
