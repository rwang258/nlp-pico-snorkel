{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffcb4bb9-12de-4189-85a3-3320ccf9be85",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data programming with Snorkel: Labeling the PICO dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e0a69cf-15ef-45ee-8861-bb873fce2904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importations.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import snorkel\n",
    "from snorkel.labeling import labeling_function\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling.model import MajorityLabelVoter\n",
    "from snorkel.labeling.model import LabelModel\n",
    "from snorkel.analysis import get_label_buckets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string # For punctuation.\n",
    "import os\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9baa17d-5e0c-4a07-b8a6-d52a309d24fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('first_sentence_file.pickle', 'rb') as handle:\n",
    "    first_sentence_file = pickle.load(handle)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73489cc0-4414-4ad9-ab40-ffd85d3f34ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Process keyword data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7dc43e5-51bc-4981-9ae5-083734b6a32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in suffixes.\n",
    "# https://druginfo.nlm.nih.gov/drugportal/jsp/drugportal/DrugNameGenericStems.jsp\n",
    "df_drugs = pd.read_csv(\"suffixes/drug_suffixes.txt\", header = None)\n",
    "df_surgery = pd.read_csv(\"suffixes/surgical_suffixes.txt\", header = None)\n",
    "df_psych = pd.read_csv(\"suffixes/psychotherapy_keywords.txt\", header = None)\n",
    "\n",
    "df_psych[0] = df_psych[0].str.lower()\n",
    "df_surgery[0] = df_surgery[0].str.lower()\n",
    "df_drugs[0] = df_drugs[0].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14a4a89e-08f7-48c3-b318-d9b82dbed512",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-bcf9fa056548>:6: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df_drugs_at_fda = pd.read_csv(\"fda_approved_drugs/products_drugs_at_fda.txt\",\n",
      "b'Skipping line 35225: expected 8 fields, saw 9\\nSkipping line 35226: expected 8 fields, saw 9\\nSkipping line 35227: expected 8 fields, saw 9\\n'\n"
     ]
    }
   ],
   "source": [
    "# Read in FDA data.\n",
    "\n",
    "df_purple = pd.read_csv(\"fda_approved_drugs/products_purplebook.csv\")\n",
    "df_orange = pd.read_csv(\"fda_approved_drugs/products_orangebook.txt\", \n",
    "                        sep = \"~\")\n",
    "df_drugs_at_fda = pd.read_csv(\"fda_approved_drugs/products_drugs_at_fda.txt\", \n",
    "                              sep = \"\\t\", \n",
    "                              error_bad_lines = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d65cb622-487c-4872-ab25-87399bfd84b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter drug suffixes with three characters or fewer.\n",
    "drug_suffixes = list(df_drugs[0])\n",
    "drug_suffixes = [x.lower() for x in drug_suffixes if len(x) > 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73432812-6063-449f-bfbd-2e8756a4b0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate FDA drug data.\n",
    "set_proprietary = list(df_drugs_at_fda[\"DrugName\"]) + list(df_purple[\"Proprietary Name\"]) + list(df_orange[\"Trade_Name\"])\n",
    "set_proper = list(df_drugs_at_fda[\"ActiveIngredient\"]) + list(df_purple[\"Proper Name\"]) + list(df_orange[\"Ingredient\"])\n",
    "\n",
    "# Remove floats and integers.\n",
    "set_proprietary = [item.lower() for item in set_proprietary if not isinstance(item, float)]\n",
    "set_proprietary = [item for item in set_proprietary if not isinstance(item, int)]\n",
    "set_proper = [item.lower() for item in set_proper if not isinstance(item, float)]\n",
    "set_proper = [item for item in set_proper if not isinstance(item, int)]\n",
    "\n",
    "# Cast as sets to remove duplicates.\n",
    "set_proprietary = set(set_proprietary)\n",
    "set_proper = set(set_proper)\n",
    "set_fda = set.union(set_proprietary, set_proper)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2442c7-c67d-4929-99aa-45f5150a6141",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bcb22ea-dfc7-4bec-bfd3-89ecfe78f5b5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read the pickle file\n",
    "with open('df_orig.pickle', 'rb') as handle:\n",
    "    df_orig = pickle.load(handle)\n",
    "\n",
    "# Remove None type labels. BERT does the same.\n",
    "df_orig = df_orig.dropna()\n",
    "df_orig = df_orig.reset_index(drop = True)\n",
    "\n",
    "# Train-test split (80% / 20%, stratified by gold label value).\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_orig[\"token\"], \n",
    "                                                    df_orig[\"gold\"], \n",
    "                                                    test_size = 0.1, \n",
    "                                                    random_state = 42)\n",
    "df_train = df_orig.iloc[X_train.index].reset_index(drop = True)\n",
    "df_test = df_orig.iloc[X_test.index].reset_index(drop = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91caec48-6839-4e1f-b32a-4bcf63765253",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Labeling functions\n",
    "\n",
    "Labeling functions will be written to cover the following intervention categories, as used by the manual annotators of this [dataset](https://github.com/bepnye/EBM-NLP):\n",
    "\n",
    "- Surgical.\n",
    "- Physical.\n",
    "- Drug.\n",
    "- Educational.\n",
    "- Psychological.\n",
    "- Other.\n",
    "- Control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c681538f-de23-409a-a9fd-311493e99fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stop words = 179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/rcw258/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Label macros.\n",
    "ABSTAIN = -1\n",
    "NOT_I = 0\n",
    "I = 1\n",
    "\n",
    "# Data for labeling functions.\n",
    "generic_interventions = [\"therap\", \"treatment\", \"intervention\",\n",
    "                         \"placebo\", \"dose\", \"control\", \"vaccin\"]\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = stopwords.words(\"english\")\n",
    "print(\"Total stop words =\", len(stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913a3071-c24f-4336-9192-65f1ab5dfe9a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Labeling functions\n",
    "**All labeling functions label tokens. The corresponding gold labels are from the \"starting span\" labels.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b3292de-a337-4cf2-9976-629fafae9335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeling function for tokens, if token is present in first sentence (title)\n",
    "@labeling_function(resources=dict(first_sentence_file=first_sentence_file))\n",
    "def in_title(x, first_sentence_file):\n",
    "    return I if x.token.lower() in first_sentence_file[x.file] else ABSTAIN\n",
    "# abstain or not_i?\n",
    "\n",
    "# Labeling function for tokens, if token is present in first sentence (title)\n",
    "@labeling_function(resources=dict(first_sentence_file=first_sentence_file))\n",
    "def in_title2(x, first_sentence_file):\n",
    "    return I if x.token.lower() in first_sentence_file[x.file] else ABSTAIN\n",
    "# abstain or not_i?\n",
    "\n",
    "# Labeling function for tokens, if token is present in first sentence (title)\n",
    "@labeling_function(resources=dict(first_sentence_file=first_sentence_file))\n",
    "def in_title3(x, first_sentence_file):\n",
    "    return I if x.token.lower() in first_sentence_file[x.file] else ABSTAIN\n",
    "# abstain or not_i?\n",
    "\n",
    "# Labeling function for tokens, if token is present in first sentence (title)\n",
    "@labeling_function(resources=dict(first_sentence_file=first_sentence_file))\n",
    "def in_title4(x, first_sentence_file):\n",
    "    return I if x.token.lower() in first_sentence_file[x.file] else ABSTAIN\n",
    "# abstain or not_i?\n",
    "\n",
    "\n",
    "# Labeling function for tokens, if token is present in first sentence (title)\n",
    "@labeling_function(resources=dict(first_sentence_file=first_sentence_file))\n",
    "def not_in_title(x, first_sentence_file):\n",
    "    return NOT_I if x.token.lower() not in first_sentence_file[x.file] else ABSTAIN\n",
    "# abstain or not_i?\n",
    "\n",
    "\n",
    "@labeling_function(resources=dict(first_sentence_file=first_sentence_file))\n",
    "def surround_in_title(x, first_sentence_file):\n",
    "    if((x.token_index>0) and (x.token_index<len(x.abstract)-1)):\n",
    "        if (x.abstract[x.token_index-1].lower() in first_sentence_file[x.file]) and (x.abstract[x.token_index+1].lower() in first_sentence_file[x.file]):\n",
    "            return I\n",
    "    \n",
    "    return ABSTAIN\n",
    "# abstain or not_i?\n",
    "\n",
    "\n",
    "# Labeling function for tokens that contain drug suffixes.\n",
    "@labeling_function()\n",
    "def contains_drug_suffix(x):\n",
    "    return I if (any(suffix.lower() in x.token.lower() for suffix in drug_suffixes)) else ABSTAIN\n",
    "    \n",
    "# Labeling function for tokens that contain surgical suffixes.\n",
    "@labeling_function()\n",
    "def contains_surgical_suffix(x):\n",
    "    return I if (any(suffix.lower() in x.token.lower() for suffix in df_surgery[0])) else ABSTAIN\n",
    "\n",
    "# Labeling function for tokens that contain psychological / psychotherapeutic keywords.\n",
    "@labeling_function()\n",
    "def contains_psych_term(x):\n",
    "    return I if (any(suffix.lower() in x.token.lower() for suffix in df_psych[0])) else ABSTAIN\n",
    "\n",
    "# Labeling function for tokens that contain generic intervention keywords.\n",
    "@labeling_function()\n",
    "def is_generic(x):\n",
    "    return I if (any(term.lower() in x.token.lower() for term in generic_interventions)) else ABSTAIN\n",
    "\n",
    "# Labeling function for stop words.\n",
    "@labeling_function()\n",
    "def is_stop_word(x):\n",
    "    return NOT_I if x.token.lower() in stop_words else ABSTAIN\n",
    "\n",
    "# Labeling function for tokens that are punctuation.\n",
    "@labeling_function()\n",
    "def is_punctuation(x):\n",
    "    return NOT_I if x.token.lower() in string.punctuation else ABSTAIN\n",
    "\n",
    "\n",
    "# Labeling function for FDA approved drugs.\n",
    "@labeling_function()\n",
    "def contains_fda_drug(x):\n",
    "    if (len(x.token) <= 5):\n",
    "        return ABSTAIN\n",
    "\n",
    "    return I if (any(x.token.lower() in drug.lower() for drug in set_fda)) else ABSTAIN\n",
    "\n",
    "\n",
    "# checks if the preceding token is 'of' or 'with' (effect of... I, treat with... I)\n",
    "@labeling_function()\n",
    "def has_prev_word_as(x):\n",
    "    words = ['of', 'with', 'receive', 'and']\n",
    "    if ((x.token_index > 0) and (x.abstract[x.token_index-1].lower() in words)):\n",
    "        return I \n",
    "\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "    \n",
    "# checks if the next token is 'group' or 'groups'\n",
    "@labeling_function()\n",
    "def has_next_word_as(x):\n",
    "    words = ['group', 'groups']\n",
    "    if ((x.token_index < len(x.abstract)-1) and (x.abstract[x.token_index+1].lower() in words)):\n",
    "        return NOT_I\n",
    "\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "    \n",
    "# Labeling function which labels a token as NOT_I if it is in the last 50% of the file tokens.\n",
    "@labeling_function()\n",
    "def has_high_idx(x):\n",
    "    percent = x.token_index / x.file_len\n",
    "    if percent > 0.50:\n",
    "        return NOT_I\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "    \n",
    "    \n",
    "    \n",
    "# Labeling function for tokens, sees if left span of token within sentence contains keyword\n",
    "@labeling_function()\n",
    "def left_span_contains(x):\n",
    "    \n",
    "    i = 0\n",
    "    while(x.abstract[i] != x.token):\n",
    "        i+=1\n",
    "        \n",
    "    count = 0\n",
    "    while(i >= 0 and count < 10):\n",
    "        if((x.abstract[i] == 'determine') or (x.abstract[i] == 'assess')):\n",
    "            return I\n",
    "        i-=1\n",
    "        count+=1\n",
    "        \n",
    "    return ABSTAIN\n",
    "# look into spouse tutorial left spans, and using 'resources' in LFs\n",
    "\n",
    "\n",
    "# checks if the preceding token is VBD, VBN (e.g. was administered)\n",
    "@labeling_function()\n",
    "def right_span_vb_pos(x):\n",
    "    if (x.token_index < len(x.abstract) - 2) and (x.pos_abstract[x.token_index+1] == 'VBD') and (x.pos_abstract[x.token_index+2] == 'VBN'):\n",
    "        return I \n",
    "\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "    \n",
    "    \n",
    "# checks if the preceding token is VBD, VBN (e.g. was administered)\n",
    "@labeling_function()\n",
    "def left_span_vb_pos(x):\n",
    "    if (x.token_index > 0) and ('V' in x.pos_abstract[x.token_index-1]):\n",
    "        return I\n",
    "\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "    \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e186e6-5b55-42d8-a953-73acdb04e2bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Apply labeling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e06f424-1595-415c-ac59-e062efbf3789",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 9288/275042 [03:10<1:33:51, 47.19it/s]"
     ]
    }
   ],
   "source": [
    "# Apply LFs to dataframe.\n",
    "lfs = [\n",
    "       #contains_psych_term, # accuracy = 0.131380\n",
    "       # is_punctuation,\n",
    "       #has_prev_word_as,\n",
    "    \n",
    "       # has_next_word_as_drug, low accuracy and coverage\n",
    "    \n",
    "       # left_span_contains,\n",
    "       # right_span_vb_pos,\n",
    "       # left_span_vb_pos,\n",
    "    \n",
    "       #negative LFs\n",
    "       is_stop_word,\n",
    "       has_next_word_as,\n",
    "       has_high_idx,\n",
    "    \n",
    "       #positive LFs\n",
    "       is_generic,\n",
    "       contains_drug_suffix,\n",
    "       contains_surgical_suffix,\n",
    "       contains_fda_drug,\n",
    "    \n",
    "#        in_title,\n",
    "#         in_title2,\n",
    "#         in_title3,\n",
    "#         in_title4,\n",
    "       # not_in_title,\n",
    "#        surround_in_title,\n",
    "\n",
    "      ]\n",
    "applier = PandasLFApplier(lfs = lfs)\n",
    "L_train = applier.apply(df = df_train)\n",
    "L_test = applier.apply(df = df_test)\n",
    "# L_dev = applier.apply(df = df_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601af81e-1583-4c1c-b8a8-39c21d30fbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#L_train\n",
    "# L_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b7fb58-3122-4040-913f-9c3c6f1455ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # %%capture\n",
    "\n",
    "# coverage_check_out, coverage_check = (L_dev != ABSTAIN).mean(axis = 0)\n",
    "# print(f\"check_out coverage: {coverage_check_out * 100:.1f}%\")\n",
    "# print(f\"check coverage: {coverage_check * 100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7ac091-85e1-4b73-b200-98bf96af3ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#L_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6ea8c7-e289-4499-81b7-524612418c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Y_train, Y_test.\n",
    "Y_train = df_train[\"gold\"].to_numpy(dtype = int)\n",
    "Y_test = df_test[\"gold\"].to_numpy(dtype = int)\n",
    "# Y_dev = df_dev[\"Gold\"].to_numpy(dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac65f849-308f-4444-a89a-c0a3324c7510",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Summarive coverage, conflicts, empirical accurcacy of LFs.\n",
    "LFAnalysis(L_train, lfs).lf_summary(Y_train)\n",
    "# LFAnalysis(L_dev, lfs).lf_summary(Y_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ba588d-1ae3-4208-a3e6-28aefdf2e54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LFAnalysis(L_test, lfs).lf_summary(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fa31de-c1ca-4661-a20d-e399b67fa264",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "'''\n",
    "# Explore buckets for patterns in discordance.\n",
    "buckets = get_label_buckets(L_train[:, 0], L_train[:, 1])\n",
    "display(buckets)\n",
    "display(df_train.iloc[buckets[(NOT_I, I)]].sample(10, random_state = 1))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08007c6b-893e-43da-81fa-c8e20261e226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Majority vote model.\n",
    "majority_model = MajorityLabelVoter()\n",
    "preds_train = majority_model.predict(L = L_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29029239-cbc5-460f-a5ce-476ac782e55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label model.\n",
    "label_model = LabelModel(cardinality = 2, verbose = True)\n",
    "label_model.fit(L_train = L_train, n_epochs = 500, log_freq = 100, seed = 123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98745ac8-e558-4350-aff7-beb7cedb758d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute model performance metrics.\n",
    "majority_scores = majority_model.score(L = L_test, Y = Y_test, \n",
    "                                       tie_break_policy = \"random\",\n",
    "                                       metrics = [\"f1\", \"accuracy\", \"precision\", \n",
    "                                                  \"recall\", \"roc_auc\", \"coverage\"])\n",
    "label_scores = label_model.score(L = L_test, Y = Y_test, \n",
    "                                 tie_break_policy = \"random\",\n",
    "                                 metrics = [\"f1\", \"accuracy\", \"precision\", \n",
    "                                            \"recall\", \"roc_auc\", \"coverage\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7a6fb6-4119-4b0c-91a4-db1ce809f717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performance metrics.\n",
    "majority_f1 = majority_scores.get(\"f1\")\n",
    "majority_acc = majority_scores.get(\"accuracy\")\n",
    "majority_prec = majority_scores.get(\"precision\")\n",
    "majority_rec = majority_scores.get(\"recall\")\n",
    "majority_roc = majority_scores.get(\"roc_auc\")\n",
    "majority_cov = majority_scores.get(\"coverage\")\n",
    "print(f\"{'Majority Model F1:':<25} {majority_f1 * 100:.1f}%\")\n",
    "print(f\"{'Majority Model Accuracy:':<25} {majority_acc * 100:.1f}%\")\n",
    "print(f\"{'Majority Model Precision:':<25} {majority_prec * 100:.1f}%\")\n",
    "print(f\"{'Majority Model Recall:':<25} {majority_rec * 100:.1f}%\")\n",
    "print(f\"{'Majority Model AUC ROC:':<25} {majority_roc * 100:.1f}%\")\n",
    "print(f\"{'Majority Model Coverage:':<25} {majority_cov * 100:.1f}%\")\n",
    "print(\"++++++++++++++++++++++++\")\n",
    "\n",
    "label_f1 = label_scores.get(\"f1\")\n",
    "label_acc = label_scores.get(\"accuracy\")\n",
    "label_prec = label_scores.get(\"precision\")\n",
    "label_rec = label_scores.get(\"recall\")\n",
    "label_roc = label_scores.get(\"roc_auc\")\n",
    "label_cov = label_scores.get(\"coverage\")\n",
    "print(f\"{'Label Model F1:':<25} {label_f1 * 100:.1f}%\")\n",
    "print(f\"{'Label Model Accuracy:':<25} {label_acc * 100:.1f}%\")\n",
    "print(f\"{'Label Model Precision:':<25} {label_prec * 100:.1f}%\")\n",
    "print(f\"{'Label Model Recall:':<25} {label_rec * 100:.1f}%\")\n",
    "print(f\"{'Label Model AUC ROC:':<25} {label_roc * 100:.1f}%\")\n",
    "print(f\"{'Label Model Coverage:':<25} {label_cov * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c46638-9b8e-4937-8a8e-fd8878554835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View \"dummy\" accuracy if predicting majority class every time.\n",
    "print(\"Accuracy if predicting majority class\", \n",
    "      df_test[\"gold\"].value_counts(normalize = True).max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
