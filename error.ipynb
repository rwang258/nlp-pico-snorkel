{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffcb4bb9-12de-4189-85a3-3320ccf9be85",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data programming with Snorkel: Error analysis of the PICO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e0a69cf-15ef-45ee-8861-bb873fce2904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importations.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import snorkel\n",
    "from snorkel.labeling import labeling_function\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling.model import MajorityLabelVoter\n",
    "from snorkel.labeling.model import LabelModel\n",
    "from snorkel.analysis import get_label_buckets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string # For punctuation.\n",
    "import os\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aed2708e-a9f4-4e2f-8bde-e743edb2d816",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('first_sentence_file.pickle', 'rb') as handle:\n",
    "    first_sentence_file = pickle.load(handle)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73489cc0-4414-4ad9-ab40-ffd85d3f34ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Process keyword data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19f8b906-d5e2-4bf9-ae79-df4b9f891ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-420a200c70bb>:18: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df_drugs_at_fda = pd.read_csv(\"lf_datasets/fda_approved_drugs/products_drugs_at_fda.txt\",\n",
      "b'Skipping line 35225: expected 8 fields, saw 9\\nSkipping line 35226: expected 8 fields, saw 9\\nSkipping line 35227: expected 8 fields, saw 9\\n'\n"
     ]
    }
   ],
   "source": [
    "# Read in suffixes.\n",
    "# https://druginfo.nlm.nih.gov/drugportal/jsp/drugportal/DrugNameGenericStems.jsp\n",
    "df_drugs = pd.read_csv(\"lf_datasets/suffixes/drug_suffixes.txt\", header = None)\n",
    "df_surgery = pd.read_csv(\"lf_datasets/suffixes/surgical_suffixes.txt\", header = None)\n",
    "df_psych = pd.read_csv(\"lf_datasets/suffixes/psychotherapy_keywords.txt\", header = None)\n",
    "\n",
    "df_psych[0] = df_psych[0].str.lower()\n",
    "df_surgery[0] = df_surgery[0].str.lower()\n",
    "df_drugs[0] = df_drugs[0].str.lower()\n",
    "\n",
    "\n",
    "\n",
    "# Read in FDA data.\n",
    "\n",
    "df_purple = pd.read_csv(\"lf_datasets/fda_approved_drugs/products_purplebook.csv\")\n",
    "df_orange = pd.read_csv(\"lf_datasets/fda_approved_drugs/products_orangebook.txt\", \n",
    "                        sep = \"~\")\n",
    "df_drugs_at_fda = pd.read_csv(\"lf_datasets/fda_approved_drugs/products_drugs_at_fda.txt\", \n",
    "                              sep = \"\\t\", \n",
    "                              error_bad_lines = False)\n",
    "\n",
    "\n",
    "\n",
    "# Filter drug suffixes with three characters or fewer.\n",
    "drug_suffixes = list(df_drugs[0])\n",
    "drug_suffixes = [x.lower() for x in drug_suffixes if len(x) > 3]\n",
    "\n",
    "# Concatenate FDA drug data.\n",
    "set_proprietary = list(df_drugs_at_fda[\"DrugName\"]) + list(df_purple[\"Proprietary Name\"]) + list(df_orange[\"Trade_Name\"])\n",
    "set_proper = list(df_drugs_at_fda[\"ActiveIngredient\"]) + list(df_purple[\"Proper Name\"]) + list(df_orange[\"Ingredient\"])\n",
    "\n",
    "# Remove floats and integers.\n",
    "set_proprietary = [item.lower() for item in set_proprietary if not isinstance(item, float)]\n",
    "set_proprietary = [item for item in set_proprietary if not isinstance(item, int)]\n",
    "set_proper = [item.lower() for item in set_proper if not isinstance(item, float)]\n",
    "set_proper = [item for item in set_proper if not isinstance(item, int)]\n",
    "\n",
    "# Cast as sets to remove duplicates.\n",
    "set_proprietary = set(set_proprietary)\n",
    "set_proper = set(set_proper)\n",
    "set_fda = set.union(set_proprietary, set_proper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2442c7-c67d-4929-99aa-45f5150a6141",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f5c0fd2-d042-4afe-9828-3a6065741ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the pickle file\n",
    "with open('df_orig.pickle', 'rb') as handle:\n",
    "    df_orig = pickle.load(handle)\n",
    "\n",
    "files_sample = random.sample(df_orig.PMID.unique().tolist(), 30)\n",
    "files_30_sel = df_orig['PMID'].apply(lambda x : x in files_sample)\n",
    "\n",
    "# original sample files\n",
    "df_sample_orig = df_orig[files_30_sel]\n",
    "df_sample_orig = df_sample_orig.reset_index(drop = True)\n",
    "\n",
    "# Remove None type labels. BERT does the same.\n",
    "df_sample = df_sample_orig.dropna()\n",
    "df_sample = df_sample.reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91caec48-6839-4e1f-b32a-4bcf63765253",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Labeling functions\n",
    "\n",
    "Labeling functions will be written to cover the following intervention categories, as used by the manual annotators of this [dataset](https://github.com/bepnye/EBM-NLP):\n",
    "\n",
    "- Surgical.\n",
    "- Physical.\n",
    "- Drug.\n",
    "- Educational.\n",
    "- Psychological.\n",
    "- Other.\n",
    "- Control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c681538f-de23-409a-a9fd-311493e99fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stop words = 179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/rcw258/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# Label macros.\n",
    "ABSTAIN = -1\n",
    "NOT_I = 0\n",
    "I = 1\n",
    "\n",
    "# Data for labeling functions.\n",
    "generic_interventions = [\"therap\", \"treatment\", \"intervention\",\n",
    "                         \"placebo\", \"dose\", \"control\", \"vaccin\"]\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = stopwords.words(\"english\")\n",
    "print(\"Total stop words =\", len(stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913a3071-c24f-4336-9192-65f1ab5dfe9a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Labeling functions\n",
    "**All labeling functions label tokens. The corresponding gold labels are from the \"starting span\" labels.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b3292de-a337-4cf2-9976-629fafae9335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeling function for tokens, if token is present in first sentence (title)\n",
    "@labeling_function(resources=dict(first_sentence_file=first_sentence_file))\n",
    "def in_title(x, first_sentence_file):\n",
    "    return I if x.token.lower() in first_sentence_file[x.file] else ABSTAIN\n",
    "# abstain or not_i?\n",
    "\n",
    "# Labeling function for tokens, if token is present in first sentence (title)\n",
    "@labeling_function(resources=dict(first_sentence_file=first_sentence_file))\n",
    "def in_title2(x, first_sentence_file):\n",
    "    return I if x.token.lower() in first_sentence_file[x.file] else ABSTAIN\n",
    "# abstain or not_i?\n",
    "\n",
    "# Labeling function for tokens, if token is present in first sentence (title)\n",
    "@labeling_function(resources=dict(first_sentence_file=first_sentence_file))\n",
    "def in_title3(x, first_sentence_file):\n",
    "    return I if x.token.lower() in first_sentence_file[x.file] else ABSTAIN\n",
    "# abstain or not_i?\n",
    "\n",
    "# Labeling function for tokens, if token is present in first sentence (title)\n",
    "@labeling_function(resources=dict(first_sentence_file=first_sentence_file))\n",
    "def in_title4(x, first_sentence_file):\n",
    "    return I if x.token.lower() in first_sentence_file[x.file] else ABSTAIN\n",
    "# abstain or not_i?\n",
    "\n",
    "\n",
    "# Labeling function for tokens, if token is present in first sentence (title)\n",
    "@labeling_function(resources=dict(first_sentence_file=first_sentence_file))\n",
    "def not_in_title(x, first_sentence_file):\n",
    "    return NOT_I if x.token.lower() not in first_sentence_file[x.file] else ABSTAIN\n",
    "# abstain or not_i?\n",
    "\n",
    "\n",
    "@labeling_function(resources=dict(first_sentence_file=first_sentence_file))\n",
    "def surround_in_title(x, first_sentence_file):\n",
    "    if((x.token_index>0) and (x.token_index<len(x.abstract)-1)):\n",
    "        if (x.abstract[x.token_index-1].lower() in first_sentence_file[x.file]) and (x.abstract[x.token_index+1].lower() in first_sentence_file[x.file]):\n",
    "            return I\n",
    "    \n",
    "    return ABSTAIN\n",
    "# abstain or not_i?\n",
    "\n",
    "\n",
    "# Labeling function for tokens that contain drug suffixes.\n",
    "@labeling_function()\n",
    "def contains_drug_suffix(x):\n",
    "    return I if (any(suffix.lower() in x.token.lower() for suffix in drug_suffixes)) else ABSTAIN\n",
    "    \n",
    "# Labeling function for tokens that contain surgical suffixes.\n",
    "@labeling_function()\n",
    "def contains_surgical_suffix(x):\n",
    "    return I if (any(suffix.lower() in x.token.lower() for suffix in df_surgery[0])) else ABSTAIN\n",
    "\n",
    "# Labeling function for tokens that contain psychological / psychotherapeutic keywords.\n",
    "@labeling_function()\n",
    "def contains_psych_term(x):\n",
    "    return I if (any(suffix.lower() in x.token.lower() for suffix in df_psych[0])) else ABSTAIN\n",
    "\n",
    "# Labeling function for tokens that contain generic intervention keywords.\n",
    "@labeling_function()\n",
    "def is_generic(x):\n",
    "    return I if (any(term.lower() in x.token.lower() for term in generic_interventions)) else ABSTAIN\n",
    "\n",
    "# Labeling function for stop words.\n",
    "@labeling_function()\n",
    "def is_stop_word(x):\n",
    "    return NOT_I if x.token.lower() in stop_words else ABSTAIN\n",
    "\n",
    "# Labeling function for tokens that are punctuation.\n",
    "@labeling_function()\n",
    "def is_punctuation(x):\n",
    "    return NOT_I if x.token.lower() in string.punctuation else ABSTAIN\n",
    "\n",
    "\n",
    "# Labeling function for FDA approved drugs.\n",
    "@labeling_function()\n",
    "def contains_fda_drug(x):\n",
    "    if (len(x.token) <= 5):\n",
    "        return ABSTAIN\n",
    "\n",
    "    return I if (any(x.token.lower() in drug.lower() for drug in set_fda)) else ABSTAIN\n",
    "\n",
    "\n",
    "# checks if the preceding token is 'of' or 'with' (effect of... I, treat with... I)\n",
    "@labeling_function()\n",
    "def has_prev_word_as(x):\n",
    "    words = ['of', 'with', 'receive', 'and']\n",
    "    if ((x.token_index > 0) and (x.abstract[x.token_index-1].lower() in words)):\n",
    "        return I \n",
    "\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "    \n",
    "# checks if the next token is 'group' or 'groups'\n",
    "@labeling_function()\n",
    "def has_next_word_as(x):\n",
    "    words = ['group', 'groups']\n",
    "    if ((x.token_index < len(x.abstract)-1) and (x.abstract[x.token_index+1].lower() in words)):\n",
    "        return NOT_I\n",
    "\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "    \n",
    "# Labeling function which labels a token as NOT_I if it is in the last 50% of the file tokens.\n",
    "@labeling_function()\n",
    "def has_high_idx(x):\n",
    "    percent = x.token_index / x.file_len\n",
    "    if percent > 0.50:\n",
    "        return NOT_I\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "    \n",
    "    \n",
    "    \n",
    "# Labeling function for tokens, sees if left span of token within sentence contains keyword\n",
    "@labeling_function()\n",
    "def left_span_contains(x):\n",
    "    \n",
    "    i = 0\n",
    "    while(x.abstract[i] != x.token):\n",
    "        i+=1\n",
    "        \n",
    "    count = 0\n",
    "    while(i >= 0 and count < 10):\n",
    "        if((x.abstract[i] == 'determine') or (x.abstract[i] == 'assess')):\n",
    "            return I\n",
    "        i-=1\n",
    "        count+=1\n",
    "        \n",
    "    return ABSTAIN\n",
    "# look into spouse tutorial left spans, and using 'resources' in LFs\n",
    "\n",
    "\n",
    "# checks if the preceding token is VBD, VBN (e.g. was administered)\n",
    "@labeling_function()\n",
    "def right_span_vb_pos(x):\n",
    "    if (x.token_index < len(x.abstract) - 2) and (x.pos_abstract[x.token_index+1] == 'VBD') and (x.pos_abstract[x.token_index+2] == 'VBN'):\n",
    "        return I \n",
    "\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "    \n",
    "    \n",
    "# checks if the preceding token is VBD, VBN (e.g. was administered)\n",
    "@labeling_function()\n",
    "def left_span_vb_pos(x):\n",
    "    if (x.token_index > 0) and ('V' in x.pos_abstract[x.token_index-1]):\n",
    "        return I\n",
    "\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99b13dea-2ca6-44be-9396-6c1cfb1f4582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([], dtype='int64')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample_orig.index[((df_sample_orig['PMID'] == '15965311') & (df_sample_orig['token_index'] == 1))]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54c1c7b-de98-4d21-99bf-db2a6b0e429d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate Error Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cec4a86-73f0-414a-8e21-82564d62fd94",
   "metadata": {},
   "source": [
    "Incorrect tokens have {* and *} surrounding it. Incorrect is defined as the majority model label being not -1 and different than the gold label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdaa3337-a6d4-439b-bbd7-b83a97acab17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8137/8137 [02:44<00:00, 49.57it/s] \n"
     ]
    }
   ],
   "source": [
    "# Apply LFs to dataframe.\n",
    "lfs = [\n",
    "       #contains_psych_term, # accuracy = 0.131380\n",
    "       # is_punctuation,\n",
    "       #has_prev_word_as,\n",
    "    \n",
    "       # has_next_word_as_drug, low accuracy and coverage\n",
    "    \n",
    "       # left_span_contains,\n",
    "       # right_span_vb_pos,\n",
    "       # left_span_vb_pos,\n",
    "    \n",
    "       #negative LFs\n",
    "       is_stop_word,\n",
    "       has_next_word_as,\n",
    "       has_high_idx,\n",
    "    \n",
    "       #positive LFs\n",
    "       is_generic,\n",
    "       contains_drug_suffix,\n",
    "       contains_surgical_suffix,\n",
    "       contains_fda_drug,\n",
    "    \n",
    "#        in_title,\n",
    "#         in_title2,\n",
    "#         in_title3,\n",
    "#         in_title4,\n",
    "       # not_in_title,\n",
    "#        surround_in_title,\n",
    "\n",
    "      ]\n",
    "applier = PandasLFApplier(lfs = lfs)\n",
    "L_train = applier.apply(df = df_sample)\n",
    "Y_train = df_sample[\"gold\"].to_numpy(dtype = int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b293080b-dbdf-4d96-ac46-b8dac4fe4cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, -1, -1, ..., -1,  0,  0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Majority vote model.\n",
    "majority_model = MajorityLabelVoter()\n",
    "preds_train = majority_model.predict(L = L_train)\n",
    "\n",
    "preds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "011c4087-0106-4126-9b46-bff4b27b0597",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['maj_pred']=pd.Series(preds_train.astype(str))\n",
    "# df_sample_orig = df_sample_orig.reset_index(drop = True)\n",
    "\n",
    "df_sample_orig['maj_pred'] = '-2'\n",
    "\n",
    "# adding maj_pred column to sample_original\n",
    "for i in range(len(df_sample)):\n",
    "    pmid = df_sample.loc[i, 'PMID']\n",
    "    token_index = df_sample.loc[i, 'token_index']\n",
    "    maj_pred = df_sample.loc[i, 'maj_pred']\n",
    "    ind = df_sample_orig.index[((df_sample_orig['PMID'] == pmid) & (df_sample_orig['token_index'] == token_index))][0]\n",
    "    df_sample_orig.loc[ind, 'maj_pred'] = maj_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b21f1d2c-e8bc-468e-b553-6b543354f264",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_sample_groups = df_sample_orig.groupby('PMID')\n",
    "\n",
    "# outputting sample files , with tokens that are gold labeled as I highlighted\n",
    "for name, group in df_sample_groups:\n",
    "    with open('error/gold/' + name + '.md', 'w') as output:\n",
    "        tokens = group.token.tolist()\n",
    "        golds = group.gold.tolist()\n",
    "        for i in range(0, len(tokens)):\n",
    "            if(golds[i]=='1'):\n",
    "                output.write('**' + tokens[i] + '** ')\n",
    "            else:\n",
    "                output.write(tokens[i] + ' ')\n",
    "        \n",
    "            \n",
    "            \n",
    "# outputting sample files, with tokens that are missed highlighted (tokens gold labeled as 1, but predicted as 0 or -1)\n",
    "for name, group in df_sample_groups:\n",
    "    with open('error/missed/' + name + '.md', 'w') as output:\n",
    "        tokens = group.token.tolist()\n",
    "        golds = group.gold.tolist()\n",
    "        preds = group.maj_pred.tolist()\n",
    "        for i in range(0, len(tokens)):\n",
    "            if((golds[i]=='1') and ((preds[i]=='-1') or (preds[i]=='0'))):\n",
    "                output.write('**' + tokens[i] + '** ')\n",
    "            else:\n",
    "                output.write(tokens[i] + ' ')\n",
    "                            \n",
    "                    \n",
    "# outputting sample files, with tokens that are mislabeled highlighted\n",
    "for name, group in df_sample_groups:\n",
    "    with open('error/wrong/' + name + '.md', 'w') as output:\n",
    "        tokens = group.token.tolist()\n",
    "        golds = group.gold.tolist()\n",
    "        preds = group.maj_pred.tolist()\n",
    "        for i in range(0, len(tokens)):\n",
    "            if(((golds[i]=='0') and (preds[i]=='1')) or ((golds[i]=='1') and (preds[i]=='0'))):\n",
    "                output.write('**' + tokens[i] + '** ')\n",
    "            else:\n",
    "                output.write(tokens[i] + ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fe8486-f0b5-4ce1-bb1d-24413316e637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
